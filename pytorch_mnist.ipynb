{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "V100",
      "authorship_tag": "ABX9TyNM3JxGU+ygeeiLuVTOwWtl",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/k94y/pytorch/blob/main/pytorch_mnist.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn.functional as f\n",
        "from torch.utils.data import DataLoader\n",
        "from torchvision import datasets, transforms\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "class MyNet(torch.nn.Module):\n",
        "    def __init__(self):\n",
        "        super(MyNet, self).__init__()\n",
        "        self.relu = torch.nn.ReLU()\n",
        "        self.silu = torch.nn.SiLU()\n",
        "        self.padding = torch.nn.ZeroPad2d(1)\n",
        "        self.pool = torch.nn.MaxPool2d(2, stride=2)\n",
        "        self.conv1 = torch.nn.Conv2d(1,16,3)\n",
        "        self.dropout = torch.nn.Dropout(0.25)\n",
        "        self.fc1 = torch.nn.Linear(16 * 14 * 14, 400)\n",
        "        self.fc2 = torch.nn.Linear(400, 100)\n",
        "        self.fc3 = torch.nn.Linear(100, 10)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.padding(x)\n",
        "        x = self.conv1(x)\n",
        "        x = self.silu(x)\n",
        "        x = self.pool(x)\n",
        "        x = x.view(x.size()[0], -1)\n",
        "        x = self.dropout(x)\n",
        "        x = self.fc1(x)\n",
        "        x = self.silu(x)\n",
        "        x = self.dropout(x)\n",
        "        x = self.fc2(x)\n",
        "        x = self.silu(x)\n",
        "        x = self.dropout(x)\n",
        "        x = self.fc3(x)\n",
        "        return f.log_softmax(x, dim=1)\n",
        "\n",
        "\n",
        "def load_MNIST(batch=128, intensity=1.0):\n",
        "    train_loader = torch.utils.data.DataLoader(\n",
        "        datasets.FashionMNIST('./data',\n",
        "                       train=True,\n",
        "                       download=True,\n",
        "                       transform=transforms.Compose([\n",
        "                           transforms.ToTensor(),\n",
        "                           transforms.Lambda(lambda x: x * intensity)\n",
        "                       ])),\n",
        "        batch_size=batch,\n",
        "        shuffle=True)\n",
        "\n",
        "    test_loader = torch.utils.data.DataLoader(\n",
        "        datasets.FashionMNIST('./data',\n",
        "                       train=False,\n",
        "                       transform=transforms.Compose([\n",
        "                           transforms.ToTensor(),\n",
        "                           transforms.Lambda(lambda x: x * intensity)\n",
        "                       ])),\n",
        "        batch_size=batch,\n",
        "        shuffle=True)\n",
        "\n",
        "    return {'train': train_loader, 'test': test_loader}\n",
        "\n",
        "\n",
        "if __name__ == '__main__':\n",
        "    # 学習回数\n",
        "    epoch = 20\n",
        "\n",
        "    # 学習結果の保存用\n",
        "    history = {\n",
        "        'train_loss': [],\n",
        "        'test_loss': [],\n",
        "        'test_acc': [],\n",
        "    }\n",
        "\n",
        "    # ネットワークを構築\n",
        "    device = torch.device(\"cuda:0\")\n",
        "    net: torch.nn.Module = MyNet()\n",
        "    net.to(device)\n",
        "\n",
        "    # MNISTのデータローダーを取得\n",
        "    loaders = load_MNIST()\n",
        "\n",
        "    optimizer = torch.optim.Adam(params=net.parameters(), lr=0.001)\n",
        "\n",
        "    for e in range(epoch):\n",
        "\n",
        "        \"\"\" Training Part\"\"\"\n",
        "        loss = None\n",
        "        # 学習開始 (再開)\n",
        "        net.train(True)  # 引数は省略可能\n",
        "        for i, (data, target) in enumerate(loaders['train']):\n",
        "            # 全結合のみのネットワークでは入力を1次元に\n",
        "            # print(data.shape)  # torch.Size([128, 1, 28, 28])\n",
        "            # data = data.view(-1, 28*28)\n",
        "            # print(data.shape)  # torch.Size([128, 784])\n",
        "\n",
        "            data, target = data.to(device), target.to(device)\n",
        "            optimizer.zero_grad()\n",
        "            output = net(data)\n",
        "            loss = f.nll_loss(output, target)\n",
        "            loss.backward()\n",
        "            optimizer.step()\n",
        "\n",
        "            if i % 10 == 0:\n",
        "                print('Training log: {} epoch ({} / 60000 train. data). Loss: {}'.format(e+1,\n",
        "                                                                                         (i+1)*128,\n",
        "                                                                                         loss.item())\n",
        "                      )\n",
        "\n",
        "        history['train_loss'].append(loss)\n",
        "\n",
        "        \"\"\" Test Part \"\"\"\n",
        "        # 学習のストップ\n",
        "        net.eval()  # または net.train(False) でも良い\n",
        "        test_loss = 0\n",
        "        correct = 0\n",
        "\n",
        "        with torch.no_grad():\n",
        "            for data, target in loaders['test']:\n",
        "                data, target = data.to(device), target.to(device)\n",
        "                output = net(data)\n",
        "                test_loss += f.nll_loss(output, target, reduction='sum').item()\n",
        "                pred = output.argmax(dim=1, keepdim=True)\n",
        "                correct += pred.eq(target.view_as(pred)).sum().item()\n",
        "\n",
        "        test_loss /= 10000\n",
        "\n",
        "        print('Test loss (avg): {}, Accuracy: {}'.format(test_loss,\n",
        "                                                         correct / 10000))\n",
        "\n",
        "        history['test_loss'].append(test_loss)\n",
        "        history['test_acc'].append(correct / 10000)\n",
        "\n",
        "    # 結果の出力と描画\n",
        "    print(history)\n",
        "    history['train_loss'] = list(map(lambda x: x.detach().cpu(), history['train_loss']))\n",
        "    plt.figure()\n",
        "    plt.plot(range(1, epoch+1), history['train_loss'], label='train_loss')\n",
        "    plt.plot(range(1, epoch+1), history['test_loss'], label='test_loss')\n",
        "    plt.xlabel('epoch')\n",
        "    plt.legend()\n",
        "    plt.savefig('loss.png')\n",
        "\n",
        "    plt.figure()\n",
        "    plt.plot(range(1, epoch+1), history['test_acc'])\n",
        "    plt.title('test accuracy')\n",
        "    plt.xlabel('epoch')\n",
        "    plt.savefig('test_acc.png')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "xoAJQmPLejh8",
        "outputId": "90a7ca85-0447-4212-90eb-19ddd85f58f7"
      },
      "execution_count": 42,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training log: 1 epoch (128 / 60000 train. data). Loss: 2.304140329360962\n",
            "Training log: 1 epoch (1408 / 60000 train. data). Loss: 1.4543596506118774\n",
            "Training log: 1 epoch (2688 / 60000 train. data). Loss: 0.9621217846870422\n",
            "Training log: 1 epoch (3968 / 60000 train. data). Loss: 0.8998009562492371\n",
            "Training log: 1 epoch (5248 / 60000 train. data). Loss: 0.958156943321228\n",
            "Training log: 1 epoch (6528 / 60000 train. data). Loss: 0.6204862594604492\n",
            "Training log: 1 epoch (7808 / 60000 train. data). Loss: 0.5795583128929138\n",
            "Training log: 1 epoch (9088 / 60000 train. data). Loss: 0.6549996137619019\n",
            "Training log: 1 epoch (10368 / 60000 train. data). Loss: 0.510727047920227\n",
            "Training log: 1 epoch (11648 / 60000 train. data). Loss: 0.5998439788818359\n",
            "Training log: 1 epoch (12928 / 60000 train. data). Loss: 0.76120924949646\n",
            "Training log: 1 epoch (14208 / 60000 train. data). Loss: 0.4946843683719635\n",
            "Training log: 1 epoch (15488 / 60000 train. data). Loss: 0.7610865235328674\n",
            "Training log: 1 epoch (16768 / 60000 train. data). Loss: 0.5197703242301941\n",
            "Training log: 1 epoch (18048 / 60000 train. data). Loss: 0.44199085235595703\n",
            "Training log: 1 epoch (19328 / 60000 train. data). Loss: 0.49476826190948486\n",
            "Training log: 1 epoch (20608 / 60000 train. data). Loss: 0.6354700326919556\n",
            "Training log: 1 epoch (21888 / 60000 train. data). Loss: 0.5287712812423706\n",
            "Training log: 1 epoch (23168 / 60000 train. data). Loss: 0.5966721177101135\n",
            "Training log: 1 epoch (24448 / 60000 train. data). Loss: 0.4695211350917816\n",
            "Training log: 1 epoch (25728 / 60000 train. data). Loss: 0.520863950252533\n",
            "Training log: 1 epoch (27008 / 60000 train. data). Loss: 0.5360761880874634\n",
            "Training log: 1 epoch (28288 / 60000 train. data). Loss: 0.3459487557411194\n",
            "Training log: 1 epoch (29568 / 60000 train. data). Loss: 0.5319284796714783\n",
            "Training log: 1 epoch (30848 / 60000 train. data). Loss: 0.46595847606658936\n",
            "Training log: 1 epoch (32128 / 60000 train. data). Loss: 0.5111552476882935\n",
            "Training log: 1 epoch (33408 / 60000 train. data). Loss: 0.474213570356369\n",
            "Training log: 1 epoch (34688 / 60000 train. data). Loss: 0.48249492049217224\n",
            "Training log: 1 epoch (35968 / 60000 train. data). Loss: 0.4417874217033386\n",
            "Training log: 1 epoch (37248 / 60000 train. data). Loss: 0.44442108273506165\n",
            "Training log: 1 epoch (38528 / 60000 train. data). Loss: 0.34143808484077454\n",
            "Training log: 1 epoch (39808 / 60000 train. data). Loss: 0.3667186498641968\n",
            "Training log: 1 epoch (41088 / 60000 train. data). Loss: 0.3997110426425934\n",
            "Training log: 1 epoch (42368 / 60000 train. data). Loss: 0.5054792761802673\n",
            "Training log: 1 epoch (43648 / 60000 train. data). Loss: 0.4690234959125519\n",
            "Training log: 1 epoch (44928 / 60000 train. data). Loss: 0.46807563304901123\n",
            "Training log: 1 epoch (46208 / 60000 train. data). Loss: 0.41458532214164734\n",
            "Training log: 1 epoch (47488 / 60000 train. data). Loss: 0.45823046565055847\n",
            "Training log: 1 epoch (48768 / 60000 train. data). Loss: 0.4481769800186157\n",
            "Training log: 1 epoch (50048 / 60000 train. data). Loss: 0.3985881507396698\n",
            "Training log: 1 epoch (51328 / 60000 train. data). Loss: 0.39414599537849426\n",
            "Training log: 1 epoch (52608 / 60000 train. data). Loss: 0.33120670914649963\n",
            "Training log: 1 epoch (53888 / 60000 train. data). Loss: 0.46167901158332825\n",
            "Training log: 1 epoch (55168 / 60000 train. data). Loss: 0.3717401921749115\n",
            "Training log: 1 epoch (56448 / 60000 train. data). Loss: 0.4080241620540619\n",
            "Training log: 1 epoch (57728 / 60000 train. data). Loss: 0.5448426008224487\n",
            "Training log: 1 epoch (59008 / 60000 train. data). Loss: 0.4368799924850464\n",
            "Test loss (avg): 0.38413303890228273, Accuracy: 0.86\n",
            "Training log: 2 epoch (128 / 60000 train. data). Loss: 0.44285643100738525\n",
            "Training log: 2 epoch (1408 / 60000 train. data). Loss: 0.38415348529815674\n",
            "Training log: 2 epoch (2688 / 60000 train. data). Loss: 0.2807543873786926\n",
            "Training log: 2 epoch (3968 / 60000 train. data). Loss: 0.42108452320098877\n",
            "Training log: 2 epoch (5248 / 60000 train. data). Loss: 0.5212351083755493\n",
            "Training log: 2 epoch (6528 / 60000 train. data). Loss: 0.36431553959846497\n",
            "Training log: 2 epoch (7808 / 60000 train. data). Loss: 0.3713999092578888\n",
            "Training log: 2 epoch (9088 / 60000 train. data). Loss: 0.3998876214027405\n",
            "Training log: 2 epoch (10368 / 60000 train. data). Loss: 0.2800688147544861\n",
            "Training log: 2 epoch (11648 / 60000 train. data). Loss: 0.3435104787349701\n",
            "Training log: 2 epoch (12928 / 60000 train. data). Loss: 0.37548425793647766\n",
            "Training log: 2 epoch (14208 / 60000 train. data). Loss: 0.23438617587089539\n",
            "Training log: 2 epoch (15488 / 60000 train. data). Loss: 0.3554565906524658\n",
            "Training log: 2 epoch (16768 / 60000 train. data). Loss: 0.32164594531059265\n",
            "Training log: 2 epoch (18048 / 60000 train. data). Loss: 0.31057387590408325\n",
            "Training log: 2 epoch (19328 / 60000 train. data). Loss: 0.32892924547195435\n",
            "Training log: 2 epoch (20608 / 60000 train. data). Loss: 0.3761084973812103\n",
            "Training log: 2 epoch (21888 / 60000 train. data). Loss: 0.34749656915664673\n",
            "Training log: 2 epoch (23168 / 60000 train. data). Loss: 0.4310232996940613\n",
            "Training log: 2 epoch (24448 / 60000 train. data). Loss: 0.3715314567089081\n",
            "Training log: 2 epoch (25728 / 60000 train. data). Loss: 0.31609827280044556\n",
            "Training log: 2 epoch (27008 / 60000 train. data). Loss: 0.409673810005188\n",
            "Training log: 2 epoch (28288 / 60000 train. data). Loss: 0.3635905385017395\n",
            "Training log: 2 epoch (29568 / 60000 train. data). Loss: 0.3178480267524719\n",
            "Training log: 2 epoch (30848 / 60000 train. data). Loss: 0.3664427399635315\n",
            "Training log: 2 epoch (32128 / 60000 train. data). Loss: 0.3425622582435608\n",
            "Training log: 2 epoch (33408 / 60000 train. data). Loss: 0.36743253469467163\n",
            "Training log: 2 epoch (34688 / 60000 train. data). Loss: 0.3920394778251648\n",
            "Training log: 2 epoch (35968 / 60000 train. data). Loss: 0.2336120754480362\n",
            "Training log: 2 epoch (37248 / 60000 train. data). Loss: 0.32608136534690857\n",
            "Training log: 2 epoch (38528 / 60000 train. data). Loss: 0.28527000546455383\n",
            "Training log: 2 epoch (39808 / 60000 train. data). Loss: 0.3192301094532013\n",
            "Training log: 2 epoch (41088 / 60000 train. data). Loss: 0.33921608328819275\n",
            "Training log: 2 epoch (42368 / 60000 train. data). Loss: 0.4765384793281555\n",
            "Training log: 2 epoch (43648 / 60000 train. data). Loss: 0.3825354278087616\n",
            "Training log: 2 epoch (44928 / 60000 train. data). Loss: 0.3048538565635681\n",
            "Training log: 2 epoch (46208 / 60000 train. data). Loss: 0.3450412154197693\n",
            "Training log: 2 epoch (47488 / 60000 train. data). Loss: 0.31818878650665283\n",
            "Training log: 2 epoch (48768 / 60000 train. data). Loss: 0.32686305046081543\n",
            "Training log: 2 epoch (50048 / 60000 train. data). Loss: 0.3030288815498352\n",
            "Training log: 2 epoch (51328 / 60000 train. data). Loss: 0.4851332902908325\n",
            "Training log: 2 epoch (52608 / 60000 train. data). Loss: 0.2375418096780777\n",
            "Training log: 2 epoch (53888 / 60000 train. data). Loss: 0.4356223940849304\n",
            "Training log: 2 epoch (55168 / 60000 train. data). Loss: 0.28483331203460693\n",
            "Training log: 2 epoch (56448 / 60000 train. data). Loss: 0.2130298763513565\n",
            "Training log: 2 epoch (57728 / 60000 train. data). Loss: 0.28367191553115845\n",
            "Training log: 2 epoch (59008 / 60000 train. data). Loss: 0.43061190843582153\n",
            "Test loss (avg): 0.33417674460411073, Accuracy: 0.8782\n",
            "Training log: 3 epoch (128 / 60000 train. data). Loss: 0.2244320511817932\n",
            "Training log: 3 epoch (1408 / 60000 train. data). Loss: 0.20034150779247284\n",
            "Training log: 3 epoch (2688 / 60000 train. data). Loss: 0.28826457262039185\n",
            "Training log: 3 epoch (3968 / 60000 train. data). Loss: 0.3503829836845398\n",
            "Training log: 3 epoch (5248 / 60000 train. data). Loss: 0.315782755613327\n",
            "Training log: 3 epoch (6528 / 60000 train. data). Loss: 0.278199166059494\n",
            "Training log: 3 epoch (7808 / 60000 train. data). Loss: 0.4222199320793152\n",
            "Training log: 3 epoch (9088 / 60000 train. data). Loss: 0.24883274734020233\n",
            "Training log: 3 epoch (10368 / 60000 train. data). Loss: 0.2820822298526764\n",
            "Training log: 3 epoch (11648 / 60000 train. data). Loss: 0.3158683478832245\n",
            "Training log: 3 epoch (12928 / 60000 train. data). Loss: 0.3331868648529053\n",
            "Training log: 3 epoch (14208 / 60000 train. data). Loss: 0.37652891874313354\n",
            "Training log: 3 epoch (15488 / 60000 train. data). Loss: 0.2829757332801819\n",
            "Training log: 3 epoch (16768 / 60000 train. data). Loss: 0.3532154858112335\n",
            "Training log: 3 epoch (18048 / 60000 train. data). Loss: 0.2730432152748108\n",
            "Training log: 3 epoch (19328 / 60000 train. data). Loss: 0.2682022154331207\n",
            "Training log: 3 epoch (20608 / 60000 train. data). Loss: 0.3127763569355011\n",
            "Training log: 3 epoch (21888 / 60000 train. data). Loss: 0.2972928583621979\n",
            "Training log: 3 epoch (23168 / 60000 train. data). Loss: 0.25623372197151184\n",
            "Training log: 3 epoch (24448 / 60000 train. data). Loss: 0.32045263051986694\n",
            "Training log: 3 epoch (25728 / 60000 train. data). Loss: 0.5245986580848694\n",
            "Training log: 3 epoch (27008 / 60000 train. data). Loss: 0.3045949339866638\n",
            "Training log: 3 epoch (28288 / 60000 train. data). Loss: 0.2473127543926239\n",
            "Training log: 3 epoch (29568 / 60000 train. data). Loss: 0.2590964436531067\n",
            "Training log: 3 epoch (30848 / 60000 train. data). Loss: 0.360764741897583\n",
            "Training log: 3 epoch (32128 / 60000 train. data). Loss: 0.28105196356773376\n",
            "Training log: 3 epoch (33408 / 60000 train. data). Loss: 0.2887705862522125\n",
            "Training log: 3 epoch (34688 / 60000 train. data). Loss: 0.2289382368326187\n",
            "Training log: 3 epoch (35968 / 60000 train. data). Loss: 0.3676893413066864\n",
            "Training log: 3 epoch (37248 / 60000 train. data). Loss: 0.3666469156742096\n",
            "Training log: 3 epoch (38528 / 60000 train. data). Loss: 0.2570519745349884\n",
            "Training log: 3 epoch (39808 / 60000 train. data). Loss: 0.24234290421009064\n",
            "Training log: 3 epoch (41088 / 60000 train. data). Loss: 0.3685588240623474\n",
            "Training log: 3 epoch (42368 / 60000 train. data). Loss: 0.3399792015552521\n",
            "Training log: 3 epoch (43648 / 60000 train. data). Loss: 0.21356751024723053\n",
            "Training log: 3 epoch (44928 / 60000 train. data). Loss: 0.4354948401451111\n",
            "Training log: 3 epoch (46208 / 60000 train. data). Loss: 0.41145390272140503\n",
            "Training log: 3 epoch (47488 / 60000 train. data). Loss: 0.4089621603488922\n",
            "Training log: 3 epoch (48768 / 60000 train. data). Loss: 0.3440312445163727\n",
            "Training log: 3 epoch (50048 / 60000 train. data). Loss: 0.3836982250213623\n",
            "Training log: 3 epoch (51328 / 60000 train. data). Loss: 0.28210413455963135\n",
            "Training log: 3 epoch (52608 / 60000 train. data). Loss: 0.37489205598831177\n",
            "Training log: 3 epoch (53888 / 60000 train. data). Loss: 0.2724277377128601\n",
            "Training log: 3 epoch (55168 / 60000 train. data). Loss: 0.35087135434150696\n",
            "Training log: 3 epoch (56448 / 60000 train. data). Loss: 0.22713983058929443\n",
            "Training log: 3 epoch (57728 / 60000 train. data). Loss: 0.23199670016765594\n",
            "Training log: 3 epoch (59008 / 60000 train. data). Loss: 0.22048956155776978\n",
            "Test loss (avg): 0.2999800678253174, Accuracy: 0.8902\n",
            "Training log: 4 epoch (128 / 60000 train. data). Loss: 0.2644229531288147\n",
            "Training log: 4 epoch (1408 / 60000 train. data). Loss: 0.2850758731365204\n",
            "Training log: 4 epoch (2688 / 60000 train. data). Loss: 0.22446435689926147\n",
            "Training log: 4 epoch (3968 / 60000 train. data). Loss: 0.29554423689842224\n",
            "Training log: 4 epoch (5248 / 60000 train. data). Loss: 0.3705412745475769\n",
            "Training log: 4 epoch (6528 / 60000 train. data). Loss: 0.39139217138290405\n",
            "Training log: 4 epoch (7808 / 60000 train. data). Loss: 0.460909366607666\n",
            "Training log: 4 epoch (9088 / 60000 train. data). Loss: 0.24728451669216156\n",
            "Training log: 4 epoch (10368 / 60000 train. data). Loss: 0.3454495370388031\n",
            "Training log: 4 epoch (11648 / 60000 train. data). Loss: 0.4242253303527832\n",
            "Training log: 4 epoch (12928 / 60000 train. data). Loss: 0.21086150407791138\n",
            "Training log: 4 epoch (14208 / 60000 train. data). Loss: 0.38303372263908386\n",
            "Training log: 4 epoch (15488 / 60000 train. data). Loss: 0.2861759662628174\n",
            "Training log: 4 epoch (16768 / 60000 train. data). Loss: 0.37942537665367126\n",
            "Training log: 4 epoch (18048 / 60000 train. data). Loss: 0.26988404989242554\n",
            "Training log: 4 epoch (19328 / 60000 train. data). Loss: 0.3426170349121094\n",
            "Training log: 4 epoch (20608 / 60000 train. data). Loss: 0.2407165765762329\n",
            "Training log: 4 epoch (21888 / 60000 train. data). Loss: 0.2639804482460022\n",
            "Training log: 4 epoch (23168 / 60000 train. data). Loss: 0.2465396374464035\n",
            "Training log: 4 epoch (24448 / 60000 train. data). Loss: 0.3839380145072937\n",
            "Training log: 4 epoch (25728 / 60000 train. data). Loss: 0.2503432631492615\n",
            "Training log: 4 epoch (27008 / 60000 train. data). Loss: 0.23466213047504425\n",
            "Training log: 4 epoch (28288 / 60000 train. data). Loss: 0.3311368525028229\n",
            "Training log: 4 epoch (29568 / 60000 train. data). Loss: 0.24471276998519897\n",
            "Training log: 4 epoch (30848 / 60000 train. data). Loss: 0.3181697726249695\n",
            "Training log: 4 epoch (32128 / 60000 train. data). Loss: 0.23785345256328583\n",
            "Training log: 4 epoch (33408 / 60000 train. data). Loss: 0.22221840918064117\n",
            "Training log: 4 epoch (34688 / 60000 train. data). Loss: 0.20689941942691803\n",
            "Training log: 4 epoch (35968 / 60000 train. data). Loss: 0.25503793358802795\n",
            "Training log: 4 epoch (37248 / 60000 train. data). Loss: 0.30802568793296814\n",
            "Training log: 4 epoch (38528 / 60000 train. data). Loss: 0.15093213319778442\n",
            "Training log: 4 epoch (39808 / 60000 train. data). Loss: 0.28774985671043396\n",
            "Training log: 4 epoch (41088 / 60000 train. data). Loss: 0.2684204578399658\n",
            "Training log: 4 epoch (42368 / 60000 train. data). Loss: 0.284866064786911\n",
            "Training log: 4 epoch (43648 / 60000 train. data). Loss: 0.23174919188022614\n",
            "Training log: 4 epoch (44928 / 60000 train. data). Loss: 0.301865816116333\n",
            "Training log: 4 epoch (46208 / 60000 train. data). Loss: 0.2519935667514801\n",
            "Training log: 4 epoch (47488 / 60000 train. data). Loss: 0.3117126226425171\n",
            "Training log: 4 epoch (48768 / 60000 train. data). Loss: 0.2939578592777252\n",
            "Training log: 4 epoch (50048 / 60000 train. data). Loss: 0.2855837345123291\n",
            "Training log: 4 epoch (51328 / 60000 train. data). Loss: 0.22303423285484314\n",
            "Training log: 4 epoch (52608 / 60000 train. data). Loss: 0.3010120987892151\n",
            "Training log: 4 epoch (53888 / 60000 train. data). Loss: 0.2457541525363922\n",
            "Training log: 4 epoch (55168 / 60000 train. data). Loss: 0.32330480217933655\n",
            "Training log: 4 epoch (56448 / 60000 train. data). Loss: 0.34952178597450256\n",
            "Training log: 4 epoch (57728 / 60000 train. data). Loss: 0.29114192724227905\n",
            "Training log: 4 epoch (59008 / 60000 train. data). Loss: 0.2798396050930023\n",
            "Test loss (avg): 0.28694864380359647, Accuracy: 0.8919\n",
            "Training log: 5 epoch (128 / 60000 train. data). Loss: 0.3217969536781311\n",
            "Training log: 5 epoch (1408 / 60000 train. data). Loss: 0.2083457112312317\n",
            "Training log: 5 epoch (2688 / 60000 train. data). Loss: 0.2307666540145874\n",
            "Training log: 5 epoch (3968 / 60000 train. data). Loss: 0.3566417694091797\n",
            "Training log: 5 epoch (5248 / 60000 train. data). Loss: 0.18922919034957886\n",
            "Training log: 5 epoch (6528 / 60000 train. data). Loss: 0.1984078288078308\n",
            "Training log: 5 epoch (7808 / 60000 train. data). Loss: 0.1974705457687378\n",
            "Training log: 5 epoch (9088 / 60000 train. data). Loss: 0.19604235887527466\n",
            "Training log: 5 epoch (10368 / 60000 train. data). Loss: 0.18015773594379425\n",
            "Training log: 5 epoch (11648 / 60000 train. data). Loss: 0.27005845308303833\n",
            "Training log: 5 epoch (12928 / 60000 train. data). Loss: 0.19802115857601166\n",
            "Training log: 5 epoch (14208 / 60000 train. data). Loss: 0.3427497446537018\n",
            "Training log: 5 epoch (15488 / 60000 train. data). Loss: 0.2082560956478119\n",
            "Training log: 5 epoch (16768 / 60000 train. data). Loss: 0.19863653182983398\n",
            "Training log: 5 epoch (18048 / 60000 train. data). Loss: 0.25097107887268066\n",
            "Training log: 5 epoch (19328 / 60000 train. data). Loss: 0.19956248998641968\n",
            "Training log: 5 epoch (20608 / 60000 train. data). Loss: 0.31769832968711853\n",
            "Training log: 5 epoch (21888 / 60000 train. data). Loss: 0.2563384473323822\n",
            "Training log: 5 epoch (23168 / 60000 train. data). Loss: 0.30458441376686096\n",
            "Training log: 5 epoch (24448 / 60000 train. data). Loss: 0.20704495906829834\n",
            "Training log: 5 epoch (25728 / 60000 train. data). Loss: 0.2856946885585785\n",
            "Training log: 5 epoch (27008 / 60000 train. data). Loss: 0.3323252201080322\n",
            "Training log: 5 epoch (28288 / 60000 train. data). Loss: 0.41871771216392517\n",
            "Training log: 5 epoch (29568 / 60000 train. data). Loss: 0.18177764117717743\n",
            "Training log: 5 epoch (30848 / 60000 train. data). Loss: 0.18582198023796082\n",
            "Training log: 5 epoch (32128 / 60000 train. data). Loss: 0.3679945766925812\n",
            "Training log: 5 epoch (33408 / 60000 train. data). Loss: 0.27061235904693604\n",
            "Training log: 5 epoch (34688 / 60000 train. data). Loss: 0.24624241888523102\n",
            "Training log: 5 epoch (35968 / 60000 train. data). Loss: 0.2692030072212219\n",
            "Training log: 5 epoch (37248 / 60000 train. data). Loss: 0.2552809417247772\n",
            "Training log: 5 epoch (38528 / 60000 train. data). Loss: 0.28260016441345215\n",
            "Training log: 5 epoch (39808 / 60000 train. data). Loss: 0.23983606696128845\n",
            "Training log: 5 epoch (41088 / 60000 train. data). Loss: 0.21558095514774323\n",
            "Training log: 5 epoch (42368 / 60000 train. data). Loss: 0.24150477349758148\n",
            "Training log: 5 epoch (43648 / 60000 train. data). Loss: 0.2676208019256592\n",
            "Training log: 5 epoch (44928 / 60000 train. data). Loss: 0.15631328523159027\n",
            "Training log: 5 epoch (46208 / 60000 train. data). Loss: 0.25404849648475647\n",
            "Training log: 5 epoch (47488 / 60000 train. data). Loss: 0.22323741018772125\n",
            "Training log: 5 epoch (48768 / 60000 train. data). Loss: 0.3497312366962433\n",
            "Training log: 5 epoch (50048 / 60000 train. data). Loss: 0.27416297793388367\n",
            "Training log: 5 epoch (51328 / 60000 train. data). Loss: 0.318209707736969\n",
            "Training log: 5 epoch (52608 / 60000 train. data). Loss: 0.14936111867427826\n",
            "Training log: 5 epoch (53888 / 60000 train. data). Loss: 0.28276365995407104\n",
            "Training log: 5 epoch (55168 / 60000 train. data). Loss: 0.3185368776321411\n",
            "Training log: 5 epoch (56448 / 60000 train. data). Loss: 0.275920033454895\n",
            "Training log: 5 epoch (57728 / 60000 train. data). Loss: 0.2381247878074646\n",
            "Training log: 5 epoch (59008 / 60000 train. data). Loss: 0.2584051787853241\n",
            "Test loss (avg): 0.2749035228729248, Accuracy: 0.898\n",
            "Training log: 6 epoch (128 / 60000 train. data). Loss: 0.2947589159011841\n",
            "Training log: 6 epoch (1408 / 60000 train. data). Loss: 0.15157610177993774\n",
            "Training log: 6 epoch (2688 / 60000 train. data). Loss: 0.24916787445545197\n",
            "Training log: 6 epoch (3968 / 60000 train. data). Loss: 0.22623077034950256\n",
            "Training log: 6 epoch (5248 / 60000 train. data). Loss: 0.38794296979904175\n",
            "Training log: 6 epoch (6528 / 60000 train. data). Loss: 0.13062161207199097\n",
            "Training log: 6 epoch (7808 / 60000 train. data). Loss: 0.24832189083099365\n",
            "Training log: 6 epoch (9088 / 60000 train. data). Loss: 0.22719785571098328\n",
            "Training log: 6 epoch (10368 / 60000 train. data). Loss: 0.1693364679813385\n",
            "Training log: 6 epoch (11648 / 60000 train. data). Loss: 0.24026329815387726\n",
            "Training log: 6 epoch (12928 / 60000 train. data). Loss: 0.18401025235652924\n",
            "Training log: 6 epoch (14208 / 60000 train. data). Loss: 0.18483053147792816\n",
            "Training log: 6 epoch (15488 / 60000 train. data). Loss: 0.20159292221069336\n",
            "Training log: 6 epoch (16768 / 60000 train. data). Loss: 0.1593356728553772\n",
            "Training log: 6 epoch (18048 / 60000 train. data). Loss: 0.18654398620128632\n",
            "Training log: 6 epoch (19328 / 60000 train. data). Loss: 0.22678346931934357\n",
            "Training log: 6 epoch (20608 / 60000 train. data). Loss: 0.2883630692958832\n",
            "Training log: 6 epoch (21888 / 60000 train. data). Loss: 0.31833115220069885\n",
            "Training log: 6 epoch (23168 / 60000 train. data). Loss: 0.38293391466140747\n",
            "Training log: 6 epoch (24448 / 60000 train. data). Loss: 0.23817980289459229\n",
            "Training log: 6 epoch (25728 / 60000 train. data). Loss: 0.14941956102848053\n",
            "Training log: 6 epoch (27008 / 60000 train. data). Loss: 0.30621981620788574\n",
            "Training log: 6 epoch (28288 / 60000 train. data). Loss: 0.2633621394634247\n",
            "Training log: 6 epoch (29568 / 60000 train. data). Loss: 0.3526601791381836\n",
            "Training log: 6 epoch (30848 / 60000 train. data). Loss: 0.15733739733695984\n",
            "Training log: 6 epoch (32128 / 60000 train. data). Loss: 0.2263062447309494\n",
            "Training log: 6 epoch (33408 / 60000 train. data). Loss: 0.24486611783504486\n",
            "Training log: 6 epoch (34688 / 60000 train. data). Loss: 0.35319480299949646\n",
            "Training log: 6 epoch (35968 / 60000 train. data). Loss: 0.1692173182964325\n",
            "Training log: 6 epoch (37248 / 60000 train. data). Loss: 0.30513155460357666\n",
            "Training log: 6 epoch (38528 / 60000 train. data). Loss: 0.23883232474327087\n",
            "Training log: 6 epoch (39808 / 60000 train. data). Loss: 0.2310163527727127\n",
            "Training log: 6 epoch (41088 / 60000 train. data). Loss: 0.17293687164783478\n",
            "Training log: 6 epoch (42368 / 60000 train. data). Loss: 0.22242316603660583\n",
            "Training log: 6 epoch (43648 / 60000 train. data). Loss: 0.3509896695613861\n",
            "Training log: 6 epoch (44928 / 60000 train. data). Loss: 0.26310116052627563\n",
            "Training log: 6 epoch (46208 / 60000 train. data). Loss: 0.2317855954170227\n",
            "Training log: 6 epoch (47488 / 60000 train. data). Loss: 0.23940196633338928\n",
            "Training log: 6 epoch (48768 / 60000 train. data). Loss: 0.25057080388069153\n",
            "Training log: 6 epoch (50048 / 60000 train. data). Loss: 0.23668725788593292\n",
            "Training log: 6 epoch (51328 / 60000 train. data). Loss: 0.15021318197250366\n",
            "Training log: 6 epoch (52608 / 60000 train. data). Loss: 0.2732941508293152\n",
            "Training log: 6 epoch (53888 / 60000 train. data). Loss: 0.1505460888147354\n",
            "Training log: 6 epoch (55168 / 60000 train. data). Loss: 0.17863290011882782\n",
            "Training log: 6 epoch (56448 / 60000 train. data). Loss: 0.2546069025993347\n",
            "Training log: 6 epoch (57728 / 60000 train. data). Loss: 0.19195368885993958\n",
            "Training log: 6 epoch (59008 / 60000 train. data). Loss: 0.29145342111587524\n",
            "Test loss (avg): 0.2669897354602814, Accuracy: 0.9015\n",
            "Training log: 7 epoch (128 / 60000 train. data). Loss: 0.22543364763259888\n",
            "Training log: 7 epoch (1408 / 60000 train. data). Loss: 0.20143748819828033\n",
            "Training log: 7 epoch (2688 / 60000 train. data). Loss: 0.20157480239868164\n",
            "Training log: 7 epoch (3968 / 60000 train. data). Loss: 0.13560107350349426\n",
            "Training log: 7 epoch (5248 / 60000 train. data). Loss: 0.25936248898506165\n",
            "Training log: 7 epoch (6528 / 60000 train. data). Loss: 0.2604507505893707\n",
            "Training log: 7 epoch (7808 / 60000 train. data). Loss: 0.20175984501838684\n",
            "Training log: 7 epoch (9088 / 60000 train. data). Loss: 0.2501891851425171\n",
            "Training log: 7 epoch (10368 / 60000 train. data). Loss: 0.32784774899482727\n",
            "Training log: 7 epoch (11648 / 60000 train. data). Loss: 0.26025447249412537\n",
            "Training log: 7 epoch (12928 / 60000 train. data). Loss: 0.15561456978321075\n",
            "Training log: 7 epoch (14208 / 60000 train. data). Loss: 0.1525316834449768\n",
            "Training log: 7 epoch (15488 / 60000 train. data). Loss: 0.1431187391281128\n",
            "Training log: 7 epoch (16768 / 60000 train. data). Loss: 0.26630762219429016\n",
            "Training log: 7 epoch (18048 / 60000 train. data). Loss: 0.2069816291332245\n",
            "Training log: 7 epoch (19328 / 60000 train. data). Loss: 0.2503145933151245\n",
            "Training log: 7 epoch (20608 / 60000 train. data). Loss: 0.16029545664787292\n",
            "Training log: 7 epoch (21888 / 60000 train. data). Loss: 0.15852461755275726\n",
            "Training log: 7 epoch (23168 / 60000 train. data). Loss: 0.3249894678592682\n",
            "Training log: 7 epoch (24448 / 60000 train. data). Loss: 0.20271927118301392\n",
            "Training log: 7 epoch (25728 / 60000 train. data). Loss: 0.21560822427272797\n",
            "Training log: 7 epoch (27008 / 60000 train. data). Loss: 0.36170288920402527\n",
            "Training log: 7 epoch (28288 / 60000 train. data). Loss: 0.1980677992105484\n",
            "Training log: 7 epoch (29568 / 60000 train. data). Loss: 0.3137705624103546\n",
            "Training log: 7 epoch (30848 / 60000 train. data). Loss: 0.2603016793727875\n",
            "Training log: 7 epoch (32128 / 60000 train. data). Loss: 0.21600663661956787\n",
            "Training log: 7 epoch (33408 / 60000 train. data). Loss: 0.24872034788131714\n",
            "Training log: 7 epoch (34688 / 60000 train. data). Loss: 0.2593550682067871\n",
            "Training log: 7 epoch (35968 / 60000 train. data). Loss: 0.31033310294151306\n",
            "Training log: 7 epoch (37248 / 60000 train. data). Loss: 0.22992351651191711\n",
            "Training log: 7 epoch (38528 / 60000 train. data). Loss: 0.10909587144851685\n",
            "Training log: 7 epoch (39808 / 60000 train. data). Loss: 0.21017076075077057\n",
            "Training log: 7 epoch (41088 / 60000 train. data). Loss: 0.24047954380512238\n",
            "Training log: 7 epoch (42368 / 60000 train. data). Loss: 0.19602827727794647\n",
            "Training log: 7 epoch (43648 / 60000 train. data). Loss: 0.23264853656291962\n",
            "Training log: 7 epoch (44928 / 60000 train. data). Loss: 0.20117810368537903\n",
            "Training log: 7 epoch (46208 / 60000 train. data). Loss: 0.3279699385166168\n",
            "Training log: 7 epoch (47488 / 60000 train. data). Loss: 0.19655361771583557\n",
            "Training log: 7 epoch (48768 / 60000 train. data). Loss: 0.3020983040332794\n",
            "Training log: 7 epoch (50048 / 60000 train. data). Loss: 0.25928476452827454\n",
            "Training log: 7 epoch (51328 / 60000 train. data). Loss: 0.24740159511566162\n",
            "Training log: 7 epoch (52608 / 60000 train. data). Loss: 0.14915554225444794\n",
            "Training log: 7 epoch (53888 / 60000 train. data). Loss: 0.23254024982452393\n",
            "Training log: 7 epoch (55168 / 60000 train. data). Loss: 0.1672445833683014\n",
            "Training log: 7 epoch (56448 / 60000 train. data). Loss: 0.2472667098045349\n",
            "Training log: 7 epoch (57728 / 60000 train. data). Loss: 0.23139747977256775\n",
            "Training log: 7 epoch (59008 / 60000 train. data). Loss: 0.2779098153114319\n",
            "Test loss (avg): 0.2584749703168869, Accuracy: 0.9061\n",
            "Training log: 8 epoch (128 / 60000 train. data). Loss: 0.21842896938323975\n",
            "Training log: 8 epoch (1408 / 60000 train. data). Loss: 0.17057330906391144\n",
            "Training log: 8 epoch (2688 / 60000 train. data). Loss: 0.1740272045135498\n",
            "Training log: 8 epoch (3968 / 60000 train. data). Loss: 0.2102365791797638\n",
            "Training log: 8 epoch (5248 / 60000 train. data). Loss: 0.13816922903060913\n",
            "Training log: 8 epoch (6528 / 60000 train. data). Loss: 0.195906862616539\n",
            "Training log: 8 epoch (7808 / 60000 train. data). Loss: 0.2667185366153717\n",
            "Training log: 8 epoch (9088 / 60000 train. data). Loss: 0.23174144327640533\n",
            "Training log: 8 epoch (10368 / 60000 train. data). Loss: 0.15927346050739288\n",
            "Training log: 8 epoch (11648 / 60000 train. data). Loss: 0.22810451686382294\n",
            "Training log: 8 epoch (12928 / 60000 train. data). Loss: 0.10415049642324448\n",
            "Training log: 8 epoch (14208 / 60000 train. data). Loss: 0.2796453833580017\n",
            "Training log: 8 epoch (15488 / 60000 train. data). Loss: 0.13799093663692474\n",
            "Training log: 8 epoch (16768 / 60000 train. data). Loss: 0.20798422396183014\n",
            "Training log: 8 epoch (18048 / 60000 train. data). Loss: 0.17602816224098206\n",
            "Training log: 8 epoch (19328 / 60000 train. data). Loss: 0.19391673803329468\n",
            "Training log: 8 epoch (20608 / 60000 train. data). Loss: 0.19848479330539703\n",
            "Training log: 8 epoch (21888 / 60000 train. data). Loss: 0.3105114996433258\n",
            "Training log: 8 epoch (23168 / 60000 train. data). Loss: 0.2718808650970459\n",
            "Training log: 8 epoch (24448 / 60000 train. data). Loss: 0.1561388373374939\n",
            "Training log: 8 epoch (25728 / 60000 train. data). Loss: 0.17628023028373718\n",
            "Training log: 8 epoch (27008 / 60000 train. data). Loss: 0.27429434657096863\n",
            "Training log: 8 epoch (28288 / 60000 train. data). Loss: 0.2537930905818939\n",
            "Training log: 8 epoch (29568 / 60000 train. data). Loss: 0.22242671251296997\n",
            "Training log: 8 epoch (30848 / 60000 train. data). Loss: 0.18414291739463806\n",
            "Training log: 8 epoch (32128 / 60000 train. data). Loss: 0.316521018743515\n",
            "Training log: 8 epoch (33408 / 60000 train. data). Loss: 0.17459248006343842\n",
            "Training log: 8 epoch (34688 / 60000 train. data). Loss: 0.2673864960670471\n",
            "Training log: 8 epoch (35968 / 60000 train. data). Loss: 0.20789547264575958\n",
            "Training log: 8 epoch (37248 / 60000 train. data). Loss: 0.2269003540277481\n",
            "Training log: 8 epoch (38528 / 60000 train. data). Loss: 0.1970185488462448\n",
            "Training log: 8 epoch (39808 / 60000 train. data). Loss: 0.23021206259727478\n",
            "Training log: 8 epoch (41088 / 60000 train. data). Loss: 0.1966448724269867\n",
            "Training log: 8 epoch (42368 / 60000 train. data). Loss: 0.15941281616687775\n",
            "Training log: 8 epoch (43648 / 60000 train. data). Loss: 0.26776692271232605\n",
            "Training log: 8 epoch (44928 / 60000 train. data). Loss: 0.21906998753547668\n",
            "Training log: 8 epoch (46208 / 60000 train. data). Loss: 0.24562788009643555\n",
            "Training log: 8 epoch (47488 / 60000 train. data). Loss: 0.20952987670898438\n",
            "Training log: 8 epoch (48768 / 60000 train. data). Loss: 0.256040096282959\n",
            "Training log: 8 epoch (50048 / 60000 train. data). Loss: 0.22894196212291718\n",
            "Training log: 8 epoch (51328 / 60000 train. data). Loss: 0.23339667916297913\n",
            "Training log: 8 epoch (52608 / 60000 train. data). Loss: 0.17817150056362152\n",
            "Training log: 8 epoch (53888 / 60000 train. data). Loss: 0.27937352657318115\n",
            "Training log: 8 epoch (55168 / 60000 train. data). Loss: 0.2934208810329437\n",
            "Training log: 8 epoch (56448 / 60000 train. data). Loss: 0.1381484568119049\n",
            "Training log: 8 epoch (57728 / 60000 train. data). Loss: 0.11679142713546753\n",
            "Training log: 8 epoch (59008 / 60000 train. data). Loss: 0.21790729463100433\n",
            "Test loss (avg): 0.2511020880937576, Accuracy: 0.9087\n",
            "Training log: 9 epoch (128 / 60000 train. data). Loss: 0.13677243888378143\n",
            "Training log: 9 epoch (1408 / 60000 train. data). Loss: 0.2651918828487396\n",
            "Training log: 9 epoch (2688 / 60000 train. data). Loss: 0.2245619297027588\n",
            "Training log: 9 epoch (3968 / 60000 train. data). Loss: 0.13124532997608185\n",
            "Training log: 9 epoch (5248 / 60000 train. data). Loss: 0.1893935352563858\n",
            "Training log: 9 epoch (6528 / 60000 train. data). Loss: 0.21181036531925201\n",
            "Training log: 9 epoch (7808 / 60000 train. data). Loss: 0.16382701694965363\n",
            "Training log: 9 epoch (9088 / 60000 train. data). Loss: 0.12707878649234772\n",
            "Training log: 9 epoch (10368 / 60000 train. data). Loss: 0.1888652890920639\n",
            "Training log: 9 epoch (11648 / 60000 train. data). Loss: 0.23714998364448547\n",
            "Training log: 9 epoch (12928 / 60000 train. data). Loss: 0.13141030073165894\n",
            "Training log: 9 epoch (14208 / 60000 train. data). Loss: 0.2340794801712036\n",
            "Training log: 9 epoch (15488 / 60000 train. data). Loss: 0.23926255106925964\n",
            "Training log: 9 epoch (16768 / 60000 train. data). Loss: 0.2662895619869232\n",
            "Training log: 9 epoch (18048 / 60000 train. data). Loss: 0.21907486021518707\n",
            "Training log: 9 epoch (19328 / 60000 train. data). Loss: 0.18795083463191986\n",
            "Training log: 9 epoch (20608 / 60000 train. data). Loss: 0.30269622802734375\n",
            "Training log: 9 epoch (21888 / 60000 train. data). Loss: 0.25047025084495544\n",
            "Training log: 9 epoch (23168 / 60000 train. data). Loss: 0.15265244245529175\n",
            "Training log: 9 epoch (24448 / 60000 train. data). Loss: 0.16620320081710815\n",
            "Training log: 9 epoch (25728 / 60000 train. data). Loss: 0.2767680585384369\n",
            "Training log: 9 epoch (27008 / 60000 train. data). Loss: 0.26252639293670654\n",
            "Training log: 9 epoch (28288 / 60000 train. data). Loss: 0.16847562789916992\n",
            "Training log: 9 epoch (29568 / 60000 train. data). Loss: 0.30622339248657227\n",
            "Training log: 9 epoch (30848 / 60000 train. data). Loss: 0.21817514300346375\n",
            "Training log: 9 epoch (32128 / 60000 train. data). Loss: 0.1575770229101181\n",
            "Training log: 9 epoch (33408 / 60000 train. data). Loss: 0.19953732192516327\n",
            "Training log: 9 epoch (34688 / 60000 train. data). Loss: 0.23534539341926575\n",
            "Training log: 9 epoch (35968 / 60000 train. data). Loss: 0.28836849331855774\n",
            "Training log: 9 epoch (37248 / 60000 train. data). Loss: 0.20122981071472168\n",
            "Training log: 9 epoch (38528 / 60000 train. data). Loss: 0.17253704369068146\n",
            "Training log: 9 epoch (39808 / 60000 train. data). Loss: 0.13854414224624634\n",
            "Training log: 9 epoch (41088 / 60000 train. data). Loss: 0.1548328846693039\n",
            "Training log: 9 epoch (42368 / 60000 train. data). Loss: 0.17083492875099182\n",
            "Training log: 9 epoch (43648 / 60000 train. data). Loss: 0.142229825258255\n",
            "Training log: 9 epoch (44928 / 60000 train. data). Loss: 0.250876247882843\n",
            "Training log: 9 epoch (46208 / 60000 train. data). Loss: 0.14053314924240112\n",
            "Training log: 9 epoch (47488 / 60000 train. data). Loss: 0.10920226573944092\n",
            "Training log: 9 epoch (48768 / 60000 train. data). Loss: 0.18248094618320465\n",
            "Training log: 9 epoch (50048 / 60000 train. data). Loss: 0.2920707166194916\n",
            "Training log: 9 epoch (51328 / 60000 train. data). Loss: 0.2225370705127716\n",
            "Training log: 9 epoch (52608 / 60000 train. data). Loss: 0.17826132476329803\n",
            "Training log: 9 epoch (53888 / 60000 train. data). Loss: 0.1290534883737564\n",
            "Training log: 9 epoch (55168 / 60000 train. data). Loss: 0.09591559320688248\n",
            "Training log: 9 epoch (56448 / 60000 train. data). Loss: 0.2127586305141449\n",
            "Training log: 9 epoch (57728 / 60000 train. data). Loss: 0.13119497895240784\n",
            "Training log: 9 epoch (59008 / 60000 train. data). Loss: 0.1543298065662384\n",
            "Test loss (avg): 0.24553310277462007, Accuracy: 0.9122\n",
            "Training log: 10 epoch (128 / 60000 train. data). Loss: 0.08842653036117554\n",
            "Training log: 10 epoch (1408 / 60000 train. data). Loss: 0.1898682713508606\n",
            "Training log: 10 epoch (2688 / 60000 train. data). Loss: 0.24128547310829163\n",
            "Training log: 10 epoch (3968 / 60000 train. data). Loss: 0.14236272871494293\n",
            "Training log: 10 epoch (5248 / 60000 train. data). Loss: 0.11351217329502106\n",
            "Training log: 10 epoch (6528 / 60000 train. data). Loss: 0.1670977622270584\n",
            "Training log: 10 epoch (7808 / 60000 train. data). Loss: 0.19861115515232086\n",
            "Training log: 10 epoch (9088 / 60000 train. data). Loss: 0.20965144038200378\n",
            "Training log: 10 epoch (10368 / 60000 train. data). Loss: 0.1301724761724472\n",
            "Training log: 10 epoch (11648 / 60000 train. data). Loss: 0.23263198137283325\n",
            "Training log: 10 epoch (12928 / 60000 train. data). Loss: 0.16032825410366058\n",
            "Training log: 10 epoch (14208 / 60000 train. data). Loss: 0.12671102583408356\n",
            "Training log: 10 epoch (15488 / 60000 train. data). Loss: 0.09184981137514114\n",
            "Training log: 10 epoch (16768 / 60000 train. data). Loss: 0.14418403804302216\n",
            "Training log: 10 epoch (18048 / 60000 train. data). Loss: 0.16994468867778778\n",
            "Training log: 10 epoch (19328 / 60000 train. data). Loss: 0.1430765837430954\n",
            "Training log: 10 epoch (20608 / 60000 train. data). Loss: 0.268726110458374\n",
            "Training log: 10 epoch (21888 / 60000 train. data). Loss: 0.12598241865634918\n",
            "Training log: 10 epoch (23168 / 60000 train. data). Loss: 0.10790576040744781\n",
            "Training log: 10 epoch (24448 / 60000 train. data). Loss: 0.28127411007881165\n",
            "Training log: 10 epoch (25728 / 60000 train. data). Loss: 0.06612501293420792\n",
            "Training log: 10 epoch (27008 / 60000 train. data). Loss: 0.2845129370689392\n",
            "Training log: 10 epoch (28288 / 60000 train. data). Loss: 0.18452703952789307\n",
            "Training log: 10 epoch (29568 / 60000 train. data). Loss: 0.26163285970687866\n",
            "Training log: 10 epoch (30848 / 60000 train. data). Loss: 0.17296157777309418\n",
            "Training log: 10 epoch (32128 / 60000 train. data). Loss: 0.22892825305461884\n",
            "Training log: 10 epoch (33408 / 60000 train. data). Loss: 0.15679843723773956\n",
            "Training log: 10 epoch (34688 / 60000 train. data). Loss: 0.18305081129074097\n",
            "Training log: 10 epoch (35968 / 60000 train. data). Loss: 0.1720086634159088\n",
            "Training log: 10 epoch (37248 / 60000 train. data). Loss: 0.18627776205539703\n",
            "Training log: 10 epoch (38528 / 60000 train. data). Loss: 0.11518347263336182\n",
            "Training log: 10 epoch (39808 / 60000 train. data). Loss: 0.13871514797210693\n",
            "Training log: 10 epoch (41088 / 60000 train. data). Loss: 0.11180813610553741\n",
            "Training log: 10 epoch (42368 / 60000 train. data). Loss: 0.13896268606185913\n",
            "Training log: 10 epoch (43648 / 60000 train. data). Loss: 0.15763911604881287\n",
            "Training log: 10 epoch (44928 / 60000 train. data). Loss: 0.21550443768501282\n",
            "Training log: 10 epoch (46208 / 60000 train. data). Loss: 0.18055568635463715\n",
            "Training log: 10 epoch (47488 / 60000 train. data). Loss: 0.24469667673110962\n",
            "Training log: 10 epoch (48768 / 60000 train. data). Loss: 0.12955538928508759\n",
            "Training log: 10 epoch (50048 / 60000 train. data). Loss: 0.15180672705173492\n",
            "Training log: 10 epoch (51328 / 60000 train. data). Loss: 0.15862172842025757\n",
            "Training log: 10 epoch (52608 / 60000 train. data). Loss: 0.154525488615036\n",
            "Training log: 10 epoch (53888 / 60000 train. data). Loss: 0.22036117315292358\n",
            "Training log: 10 epoch (55168 / 60000 train. data). Loss: 0.15455491840839386\n",
            "Training log: 10 epoch (56448 / 60000 train. data). Loss: 0.18556222319602966\n",
            "Training log: 10 epoch (57728 / 60000 train. data). Loss: 0.22977983951568604\n",
            "Training log: 10 epoch (59008 / 60000 train. data). Loss: 0.17879419028759003\n",
            "Test loss (avg): 0.24944661436080934, Accuracy: 0.9151\n",
            "Training log: 11 epoch (128 / 60000 train. data). Loss: 0.16174262762069702\n",
            "Training log: 11 epoch (1408 / 60000 train. data). Loss: 0.14538154006004333\n",
            "Training log: 11 epoch (2688 / 60000 train. data). Loss: 0.12898772954940796\n",
            "Training log: 11 epoch (3968 / 60000 train. data). Loss: 0.16692905128002167\n",
            "Training log: 11 epoch (5248 / 60000 train. data). Loss: 0.19116318225860596\n",
            "Training log: 11 epoch (6528 / 60000 train. data). Loss: 0.19616498053073883\n",
            "Training log: 11 epoch (7808 / 60000 train. data). Loss: 0.17514069378376007\n",
            "Training log: 11 epoch (9088 / 60000 train. data). Loss: 0.17787544429302216\n",
            "Training log: 11 epoch (10368 / 60000 train. data). Loss: 0.12485238164663315\n",
            "Training log: 11 epoch (11648 / 60000 train. data). Loss: 0.2301880568265915\n",
            "Training log: 11 epoch (12928 / 60000 train. data). Loss: 0.20566941797733307\n",
            "Training log: 11 epoch (14208 / 60000 train. data). Loss: 0.16738566756248474\n",
            "Training log: 11 epoch (15488 / 60000 train. data). Loss: 0.08933617919683456\n",
            "Training log: 11 epoch (16768 / 60000 train. data). Loss: 0.2186184674501419\n",
            "Training log: 11 epoch (18048 / 60000 train. data). Loss: 0.19360746443271637\n",
            "Training log: 11 epoch (19328 / 60000 train. data). Loss: 0.20212720334529877\n",
            "Training log: 11 epoch (20608 / 60000 train. data). Loss: 0.21281081438064575\n",
            "Training log: 11 epoch (21888 / 60000 train. data). Loss: 0.22509954869747162\n",
            "Training log: 11 epoch (23168 / 60000 train. data). Loss: 0.15375109016895294\n",
            "Training log: 11 epoch (24448 / 60000 train. data). Loss: 0.1565326303243637\n",
            "Training log: 11 epoch (25728 / 60000 train. data). Loss: 0.18491342663764954\n",
            "Training log: 11 epoch (27008 / 60000 train. data). Loss: 0.12490413337945938\n",
            "Training log: 11 epoch (28288 / 60000 train. data). Loss: 0.17982572317123413\n",
            "Training log: 11 epoch (29568 / 60000 train. data). Loss: 0.16737724840641022\n",
            "Training log: 11 epoch (30848 / 60000 train. data). Loss: 0.2362520843744278\n",
            "Training log: 11 epoch (32128 / 60000 train. data). Loss: 0.18082799017429352\n",
            "Training log: 11 epoch (33408 / 60000 train. data). Loss: 0.14745505154132843\n",
            "Training log: 11 epoch (34688 / 60000 train. data). Loss: 0.10934978723526001\n",
            "Training log: 11 epoch (35968 / 60000 train. data). Loss: 0.17454981803894043\n",
            "Training log: 11 epoch (37248 / 60000 train. data). Loss: 0.11155218631029129\n",
            "Training log: 11 epoch (38528 / 60000 train. data). Loss: 0.1486862301826477\n",
            "Training log: 11 epoch (39808 / 60000 train. data). Loss: 0.17802374064922333\n",
            "Training log: 11 epoch (41088 / 60000 train. data). Loss: 0.19224180281162262\n",
            "Training log: 11 epoch (42368 / 60000 train. data). Loss: 0.14853110909461975\n",
            "Training log: 11 epoch (43648 / 60000 train. data). Loss: 0.1975434422492981\n",
            "Training log: 11 epoch (44928 / 60000 train. data). Loss: 0.19698600471019745\n",
            "Training log: 11 epoch (46208 / 60000 train. data). Loss: 0.14856389164924622\n",
            "Training log: 11 epoch (47488 / 60000 train. data). Loss: 0.15537047386169434\n",
            "Training log: 11 epoch (48768 / 60000 train. data). Loss: 0.20707185566425323\n",
            "Training log: 11 epoch (50048 / 60000 train. data). Loss: 0.24254055321216583\n",
            "Training log: 11 epoch (51328 / 60000 train. data). Loss: 0.22024807333946228\n",
            "Training log: 11 epoch (52608 / 60000 train. data). Loss: 0.1552749127149582\n",
            "Training log: 11 epoch (53888 / 60000 train. data). Loss: 0.21746227145195007\n",
            "Training log: 11 epoch (55168 / 60000 train. data). Loss: 0.1889457106590271\n",
            "Training log: 11 epoch (56448 / 60000 train. data). Loss: 0.2082846462726593\n",
            "Training log: 11 epoch (57728 / 60000 train. data). Loss: 0.16171656548976898\n",
            "Training log: 11 epoch (59008 / 60000 train. data). Loss: 0.28577902913093567\n",
            "Test loss (avg): 0.2500010194659233, Accuracy: 0.9134\n",
            "Training log: 12 epoch (128 / 60000 train. data). Loss: 0.13458558917045593\n",
            "Training log: 12 epoch (1408 / 60000 train. data). Loss: 0.2199995368719101\n",
            "Training log: 12 epoch (2688 / 60000 train. data). Loss: 0.09776948392391205\n",
            "Training log: 12 epoch (3968 / 60000 train. data). Loss: 0.20186035335063934\n",
            "Training log: 12 epoch (5248 / 60000 train. data). Loss: 0.2377105951309204\n",
            "Training log: 12 epoch (6528 / 60000 train. data). Loss: 0.13240590691566467\n",
            "Training log: 12 epoch (7808 / 60000 train. data). Loss: 0.18382824957370758\n",
            "Training log: 12 epoch (9088 / 60000 train. data). Loss: 0.10907456278800964\n",
            "Training log: 12 epoch (10368 / 60000 train. data). Loss: 0.10210904479026794\n",
            "Training log: 12 epoch (11648 / 60000 train. data). Loss: 0.13268053531646729\n",
            "Training log: 12 epoch (12928 / 60000 train. data). Loss: 0.15180867910385132\n",
            "Training log: 12 epoch (14208 / 60000 train. data). Loss: 0.17583660781383514\n",
            "Training log: 12 epoch (15488 / 60000 train. data). Loss: 0.24230794608592987\n",
            "Training log: 12 epoch (16768 / 60000 train. data). Loss: 0.18001699447631836\n",
            "Training log: 12 epoch (18048 / 60000 train. data). Loss: 0.17447499930858612\n",
            "Training log: 12 epoch (19328 / 60000 train. data). Loss: 0.20534639060497284\n",
            "Training log: 12 epoch (20608 / 60000 train. data). Loss: 0.27196863293647766\n",
            "Training log: 12 epoch (21888 / 60000 train. data). Loss: 0.20889967679977417\n",
            "Training log: 12 epoch (23168 / 60000 train. data). Loss: 0.1564587950706482\n",
            "Training log: 12 epoch (24448 / 60000 train. data). Loss: 0.1986353099346161\n",
            "Training log: 12 epoch (25728 / 60000 train. data). Loss: 0.16520361602306366\n",
            "Training log: 12 epoch (27008 / 60000 train. data). Loss: 0.210434228181839\n",
            "Training log: 12 epoch (28288 / 60000 train. data). Loss: 0.11234770715236664\n",
            "Training log: 12 epoch (29568 / 60000 train. data). Loss: 0.10593867301940918\n",
            "Training log: 12 epoch (30848 / 60000 train. data). Loss: 0.11421284079551697\n",
            "Training log: 12 epoch (32128 / 60000 train. data). Loss: 0.18454724550247192\n",
            "Training log: 12 epoch (33408 / 60000 train. data). Loss: 0.15544378757476807\n",
            "Training log: 12 epoch (34688 / 60000 train. data). Loss: 0.19409646093845367\n",
            "Training log: 12 epoch (35968 / 60000 train. data). Loss: 0.17250268161296844\n",
            "Training log: 12 epoch (37248 / 60000 train. data). Loss: 0.16864065825939178\n",
            "Training log: 12 epoch (38528 / 60000 train. data). Loss: 0.1591273993253708\n",
            "Training log: 12 epoch (39808 / 60000 train. data). Loss: 0.22356948256492615\n",
            "Training log: 12 epoch (41088 / 60000 train. data). Loss: 0.151666522026062\n",
            "Training log: 12 epoch (42368 / 60000 train. data). Loss: 0.1411781907081604\n",
            "Training log: 12 epoch (43648 / 60000 train. data). Loss: 0.20056967437267303\n",
            "Training log: 12 epoch (44928 / 60000 train. data). Loss: 0.15838533639907837\n",
            "Training log: 12 epoch (46208 / 60000 train. data). Loss: 0.2009628713130951\n",
            "Training log: 12 epoch (47488 / 60000 train. data). Loss: 0.08985380828380585\n",
            "Training log: 12 epoch (48768 / 60000 train. data). Loss: 0.20257490873336792\n",
            "Training log: 12 epoch (50048 / 60000 train. data). Loss: 0.1501000076532364\n",
            "Training log: 12 epoch (51328 / 60000 train. data). Loss: 0.10068713128566742\n",
            "Training log: 12 epoch (52608 / 60000 train. data). Loss: 0.21931149065494537\n",
            "Training log: 12 epoch (53888 / 60000 train. data). Loss: 0.19337880611419678\n",
            "Training log: 12 epoch (55168 / 60000 train. data). Loss: 0.11318502575159073\n",
            "Training log: 12 epoch (56448 / 60000 train. data). Loss: 0.2227717936038971\n",
            "Training log: 12 epoch (57728 / 60000 train. data). Loss: 0.11796152591705322\n",
            "Training log: 12 epoch (59008 / 60000 train. data). Loss: 0.1371707320213318\n",
            "Test loss (avg): 0.2488769595146179, Accuracy: 0.9159\n",
            "Training log: 13 epoch (128 / 60000 train. data). Loss: 0.09648142009973526\n",
            "Training log: 13 epoch (1408 / 60000 train. data). Loss: 0.17569682002067566\n",
            "Training log: 13 epoch (2688 / 60000 train. data). Loss: 0.14477472007274628\n",
            "Training log: 13 epoch (3968 / 60000 train. data). Loss: 0.20642918348312378\n",
            "Training log: 13 epoch (5248 / 60000 train. data). Loss: 0.1186298355460167\n",
            "Training log: 13 epoch (6528 / 60000 train. data). Loss: 0.11769434809684753\n",
            "Training log: 13 epoch (7808 / 60000 train. data). Loss: 0.16951201856136322\n",
            "Training log: 13 epoch (9088 / 60000 train. data). Loss: 0.11741209775209427\n",
            "Training log: 13 epoch (10368 / 60000 train. data). Loss: 0.17215833067893982\n",
            "Training log: 13 epoch (11648 / 60000 train. data). Loss: 0.09149462729692459\n",
            "Training log: 13 epoch (12928 / 60000 train. data). Loss: 0.12926097214221954\n",
            "Training log: 13 epoch (14208 / 60000 train. data). Loss: 0.17060060799121857\n",
            "Training log: 13 epoch (15488 / 60000 train. data). Loss: 0.08980192244052887\n",
            "Training log: 13 epoch (16768 / 60000 train. data). Loss: 0.09927476942539215\n",
            "Training log: 13 epoch (18048 / 60000 train. data). Loss: 0.1318705528974533\n",
            "Training log: 13 epoch (19328 / 60000 train. data). Loss: 0.1305244266986847\n",
            "Training log: 13 epoch (20608 / 60000 train. data). Loss: 0.13980937004089355\n",
            "Training log: 13 epoch (21888 / 60000 train. data). Loss: 0.14441844820976257\n",
            "Training log: 13 epoch (23168 / 60000 train. data). Loss: 0.1691916137933731\n",
            "Training log: 13 epoch (24448 / 60000 train. data). Loss: 0.1525501161813736\n",
            "Training log: 13 epoch (25728 / 60000 train. data). Loss: 0.17687033116817474\n",
            "Training log: 13 epoch (27008 / 60000 train. data). Loss: 0.19245903193950653\n",
            "Training log: 13 epoch (28288 / 60000 train. data). Loss: 0.16224557161331177\n",
            "Training log: 13 epoch (29568 / 60000 train. data). Loss: 0.11805941164493561\n",
            "Training log: 13 epoch (30848 / 60000 train. data). Loss: 0.1999303102493286\n",
            "Training log: 13 epoch (32128 / 60000 train. data). Loss: 0.15244387090206146\n",
            "Training log: 13 epoch (33408 / 60000 train. data). Loss: 0.08137127012014389\n",
            "Training log: 13 epoch (34688 / 60000 train. data). Loss: 0.21051615476608276\n",
            "Training log: 13 epoch (35968 / 60000 train. data). Loss: 0.18208210170269012\n",
            "Training log: 13 epoch (37248 / 60000 train. data). Loss: 0.12099733203649521\n",
            "Training log: 13 epoch (38528 / 60000 train. data). Loss: 0.22186312079429626\n",
            "Training log: 13 epoch (39808 / 60000 train. data). Loss: 0.19255472719669342\n",
            "Training log: 13 epoch (41088 / 60000 train. data). Loss: 0.1418161392211914\n",
            "Training log: 13 epoch (42368 / 60000 train. data). Loss: 0.10314638912677765\n",
            "Training log: 13 epoch (43648 / 60000 train. data). Loss: 0.13056626915931702\n",
            "Training log: 13 epoch (44928 / 60000 train. data). Loss: 0.13596104085445404\n",
            "Training log: 13 epoch (46208 / 60000 train. data). Loss: 0.17613255977630615\n",
            "Training log: 13 epoch (47488 / 60000 train. data). Loss: 0.13497599959373474\n",
            "Training log: 13 epoch (48768 / 60000 train. data). Loss: 0.21293368935585022\n",
            "Training log: 13 epoch (50048 / 60000 train. data). Loss: 0.1300230473279953\n",
            "Training log: 13 epoch (51328 / 60000 train. data). Loss: 0.17113998532295227\n",
            "Training log: 13 epoch (52608 / 60000 train. data). Loss: 0.08941402286291122\n",
            "Training log: 13 epoch (53888 / 60000 train. data). Loss: 0.11749289184808731\n",
            "Training log: 13 epoch (55168 / 60000 train. data). Loss: 0.14768530428409576\n",
            "Training log: 13 epoch (56448 / 60000 train. data). Loss: 0.0528222918510437\n",
            "Training log: 13 epoch (57728 / 60000 train. data). Loss: 0.19459378719329834\n",
            "Training log: 13 epoch (59008 / 60000 train. data). Loss: 0.14302942156791687\n",
            "Test loss (avg): 0.25329789714813233, Accuracy: 0.9151\n",
            "Training log: 14 epoch (128 / 60000 train. data). Loss: 0.12942618131637573\n",
            "Training log: 14 epoch (1408 / 60000 train. data). Loss: 0.21209916472434998\n",
            "Training log: 14 epoch (2688 / 60000 train. data). Loss: 0.17015869915485382\n",
            "Training log: 14 epoch (3968 / 60000 train. data). Loss: 0.07830625027418137\n",
            "Training log: 14 epoch (5248 / 60000 train. data). Loss: 0.12074913084506989\n",
            "Training log: 14 epoch (6528 / 60000 train. data). Loss: 0.1123724952340126\n",
            "Training log: 14 epoch (7808 / 60000 train. data). Loss: 0.16919051110744476\n",
            "Training log: 14 epoch (9088 / 60000 train. data). Loss: 0.16272880136966705\n",
            "Training log: 14 epoch (10368 / 60000 train. data). Loss: 0.09794305264949799\n",
            "Training log: 14 epoch (11648 / 60000 train. data). Loss: 0.07333113253116608\n",
            "Training log: 14 epoch (12928 / 60000 train. data). Loss: 0.16851739585399628\n",
            "Training log: 14 epoch (14208 / 60000 train. data). Loss: 0.17612627148628235\n",
            "Training log: 14 epoch (15488 / 60000 train. data). Loss: 0.09475116431713104\n",
            "Training log: 14 epoch (16768 / 60000 train. data). Loss: 0.15036866068840027\n",
            "Training log: 14 epoch (18048 / 60000 train. data). Loss: 0.240259051322937\n",
            "Training log: 14 epoch (19328 / 60000 train. data). Loss: 0.14080819487571716\n",
            "Training log: 14 epoch (20608 / 60000 train. data). Loss: 0.146138995885849\n",
            "Training log: 14 epoch (21888 / 60000 train. data). Loss: 0.09631331264972687\n",
            "Training log: 14 epoch (23168 / 60000 train. data). Loss: 0.12626293301582336\n",
            "Training log: 14 epoch (24448 / 60000 train. data). Loss: 0.10785005986690521\n",
            "Training log: 14 epoch (25728 / 60000 train. data). Loss: 0.13438689708709717\n",
            "Training log: 14 epoch (27008 / 60000 train. data). Loss: 0.1912756860256195\n",
            "Training log: 14 epoch (28288 / 60000 train. data). Loss: 0.11623932421207428\n",
            "Training log: 14 epoch (29568 / 60000 train. data). Loss: 0.13400794565677643\n",
            "Training log: 14 epoch (30848 / 60000 train. data). Loss: 0.1430872529745102\n",
            "Training log: 14 epoch (32128 / 60000 train. data). Loss: 0.13187284767627716\n",
            "Training log: 14 epoch (33408 / 60000 train. data). Loss: 0.06562740355730057\n",
            "Training log: 14 epoch (34688 / 60000 train. data). Loss: 0.13183988630771637\n",
            "Training log: 14 epoch (35968 / 60000 train. data). Loss: 0.1513843834400177\n",
            "Training log: 14 epoch (37248 / 60000 train. data). Loss: 0.11180166155099869\n",
            "Training log: 14 epoch (38528 / 60000 train. data). Loss: 0.12123481184244156\n",
            "Training log: 14 epoch (39808 / 60000 train. data). Loss: 0.2081805169582367\n",
            "Training log: 14 epoch (41088 / 60000 train. data). Loss: 0.11903653293848038\n",
            "Training log: 14 epoch (42368 / 60000 train. data). Loss: 0.09008687734603882\n",
            "Training log: 14 epoch (43648 / 60000 train. data). Loss: 0.09848329424858093\n",
            "Training log: 14 epoch (44928 / 60000 train. data). Loss: 0.11947282403707504\n",
            "Training log: 14 epoch (46208 / 60000 train. data). Loss: 0.09595774859189987\n",
            "Training log: 14 epoch (47488 / 60000 train. data). Loss: 0.16631676256656647\n",
            "Training log: 14 epoch (48768 / 60000 train. data). Loss: 0.22408320009708405\n",
            "Training log: 14 epoch (50048 / 60000 train. data). Loss: 0.1126805990934372\n",
            "Training log: 14 epoch (51328 / 60000 train. data). Loss: 0.18634073436260223\n",
            "Training log: 14 epoch (52608 / 60000 train. data). Loss: 0.1777123063802719\n",
            "Training log: 14 epoch (53888 / 60000 train. data). Loss: 0.28279057145118713\n",
            "Training log: 14 epoch (55168 / 60000 train. data). Loss: 0.1691984385251999\n",
            "Training log: 14 epoch (56448 / 60000 train. data). Loss: 0.11881215125322342\n",
            "Training log: 14 epoch (57728 / 60000 train. data). Loss: 0.08523844927549362\n",
            "Training log: 14 epoch (59008 / 60000 train. data). Loss: 0.10181187838315964\n",
            "Test loss (avg): 0.2532062297821045, Accuracy: 0.9172\n",
            "Training log: 15 epoch (128 / 60000 train. data). Loss: 0.1403772234916687\n",
            "Training log: 15 epoch (1408 / 60000 train. data). Loss: 0.1986132562160492\n",
            "Training log: 15 epoch (2688 / 60000 train. data). Loss: 0.12254301458597183\n",
            "Training log: 15 epoch (3968 / 60000 train. data). Loss: 0.14472796022891998\n",
            "Training log: 15 epoch (5248 / 60000 train. data). Loss: 0.12646052241325378\n",
            "Training log: 15 epoch (6528 / 60000 train. data). Loss: 0.14848679304122925\n",
            "Training log: 15 epoch (7808 / 60000 train. data). Loss: 0.14951355755329132\n",
            "Training log: 15 epoch (9088 / 60000 train. data). Loss: 0.10345926880836487\n",
            "Training log: 15 epoch (10368 / 60000 train. data). Loss: 0.11463728547096252\n",
            "Training log: 15 epoch (11648 / 60000 train. data). Loss: 0.10740741342306137\n",
            "Training log: 15 epoch (12928 / 60000 train. data). Loss: 0.16059255599975586\n",
            "Training log: 15 epoch (14208 / 60000 train. data). Loss: 0.10158238559961319\n",
            "Training log: 15 epoch (15488 / 60000 train. data). Loss: 0.07299179583787918\n",
            "Training log: 15 epoch (16768 / 60000 train. data). Loss: 0.07152733951807022\n",
            "Training log: 15 epoch (18048 / 60000 train. data). Loss: 0.15764139592647552\n",
            "Training log: 15 epoch (19328 / 60000 train. data). Loss: 0.1685243546962738\n",
            "Training log: 15 epoch (20608 / 60000 train. data). Loss: 0.11815783381462097\n",
            "Training log: 15 epoch (21888 / 60000 train. data). Loss: 0.15113608539104462\n",
            "Training log: 15 epoch (23168 / 60000 train. data). Loss: 0.07022514194250107\n",
            "Training log: 15 epoch (24448 / 60000 train. data). Loss: 0.09574975073337555\n",
            "Training log: 15 epoch (25728 / 60000 train. data). Loss: 0.11666853725910187\n",
            "Training log: 15 epoch (27008 / 60000 train. data). Loss: 0.1835639625787735\n",
            "Training log: 15 epoch (28288 / 60000 train. data). Loss: 0.0957249253988266\n",
            "Training log: 15 epoch (29568 / 60000 train. data). Loss: 0.13726255297660828\n",
            "Training log: 15 epoch (30848 / 60000 train. data). Loss: 0.18599443137645721\n",
            "Training log: 15 epoch (32128 / 60000 train. data). Loss: 0.09427852928638458\n",
            "Training log: 15 epoch (33408 / 60000 train. data). Loss: 0.08210980892181396\n",
            "Training log: 15 epoch (34688 / 60000 train. data). Loss: 0.14627578854560852\n",
            "Training log: 15 epoch (35968 / 60000 train. data). Loss: 0.2989029586315155\n",
            "Training log: 15 epoch (37248 / 60000 train. data). Loss: 0.04072592779994011\n",
            "Training log: 15 epoch (38528 / 60000 train. data). Loss: 0.11426204442977905\n",
            "Training log: 15 epoch (39808 / 60000 train. data). Loss: 0.16685262322425842\n",
            "Training log: 15 epoch (41088 / 60000 train. data). Loss: 0.12232258915901184\n",
            "Training log: 15 epoch (42368 / 60000 train. data). Loss: 0.11132747679948807\n",
            "Training log: 15 epoch (43648 / 60000 train. data). Loss: 0.07602787762880325\n",
            "Training log: 15 epoch (44928 / 60000 train. data). Loss: 0.18473030626773834\n",
            "Training log: 15 epoch (46208 / 60000 train. data). Loss: 0.08515697717666626\n",
            "Training log: 15 epoch (47488 / 60000 train. data). Loss: 0.15004344284534454\n",
            "Training log: 15 epoch (48768 / 60000 train. data). Loss: 0.1183602586388588\n",
            "Training log: 15 epoch (50048 / 60000 train. data). Loss: 0.0453459732234478\n",
            "Training log: 15 epoch (51328 / 60000 train. data). Loss: 0.18831375241279602\n",
            "Training log: 15 epoch (52608 / 60000 train. data). Loss: 0.10714267939329147\n",
            "Training log: 15 epoch (53888 / 60000 train. data). Loss: 0.08587382733821869\n",
            "Training log: 15 epoch (55168 / 60000 train. data). Loss: 0.12115266919136047\n",
            "Training log: 15 epoch (56448 / 60000 train. data). Loss: 0.19402186572551727\n",
            "Training log: 15 epoch (57728 / 60000 train. data). Loss: 0.12498589605093002\n",
            "Training log: 15 epoch (59008 / 60000 train. data). Loss: 0.1235777959227562\n",
            "Test loss (avg): 0.24398050694465637, Accuracy: 0.921\n",
            "Training log: 16 epoch (128 / 60000 train. data). Loss: 0.07676897197961807\n",
            "Training log: 16 epoch (1408 / 60000 train. data). Loss: 0.06868401169776917\n",
            "Training log: 16 epoch (2688 / 60000 train. data). Loss: 0.06553395092487335\n",
            "Training log: 16 epoch (3968 / 60000 train. data). Loss: 0.1713356375694275\n",
            "Training log: 16 epoch (5248 / 60000 train. data). Loss: 0.1247558519244194\n",
            "Training log: 16 epoch (6528 / 60000 train. data). Loss: 0.10739374905824661\n",
            "Training log: 16 epoch (7808 / 60000 train. data). Loss: 0.09744270145893097\n",
            "Training log: 16 epoch (9088 / 60000 train. data). Loss: 0.09536106139421463\n",
            "Training log: 16 epoch (10368 / 60000 train. data). Loss: 0.23734799027442932\n",
            "Training log: 16 epoch (11648 / 60000 train. data). Loss: 0.08553861081600189\n",
            "Training log: 16 epoch (12928 / 60000 train. data). Loss: 0.06703750789165497\n",
            "Training log: 16 epoch (14208 / 60000 train. data). Loss: 0.13536255061626434\n",
            "Training log: 16 epoch (15488 / 60000 train. data). Loss: 0.1327306479215622\n",
            "Training log: 16 epoch (16768 / 60000 train. data). Loss: 0.09808362275362015\n",
            "Training log: 16 epoch (18048 / 60000 train. data). Loss: 0.17739620804786682\n",
            "Training log: 16 epoch (19328 / 60000 train. data). Loss: 0.09866219758987427\n",
            "Training log: 16 epoch (20608 / 60000 train. data). Loss: 0.10965684801340103\n",
            "Training log: 16 epoch (21888 / 60000 train. data). Loss: 0.13410168886184692\n",
            "Training log: 16 epoch (23168 / 60000 train. data). Loss: 0.09764523059129715\n",
            "Training log: 16 epoch (24448 / 60000 train. data). Loss: 0.06707818061113358\n",
            "Training log: 16 epoch (25728 / 60000 train. data). Loss: 0.1607702225446701\n",
            "Training log: 16 epoch (27008 / 60000 train. data). Loss: 0.1623067706823349\n",
            "Training log: 16 epoch (28288 / 60000 train. data). Loss: 0.09460679441690445\n",
            "Training log: 16 epoch (29568 / 60000 train. data). Loss: 0.11635533720254898\n",
            "Training log: 16 epoch (30848 / 60000 train. data). Loss: 0.09742945432662964\n",
            "Training log: 16 epoch (32128 / 60000 train. data). Loss: 0.06640377640724182\n",
            "Training log: 16 epoch (33408 / 60000 train. data). Loss: 0.10121814906597137\n",
            "Training log: 16 epoch (34688 / 60000 train. data). Loss: 0.1012125015258789\n",
            "Training log: 16 epoch (35968 / 60000 train. data). Loss: 0.09574662894010544\n",
            "Training log: 16 epoch (37248 / 60000 train. data). Loss: 0.15652230381965637\n",
            "Training log: 16 epoch (38528 / 60000 train. data). Loss: 0.13213826715946198\n",
            "Training log: 16 epoch (39808 / 60000 train. data). Loss: 0.11953727900981903\n",
            "Training log: 16 epoch (41088 / 60000 train. data). Loss: 0.10401395708322525\n",
            "Training log: 16 epoch (42368 / 60000 train. data). Loss: 0.14685769379138947\n",
            "Training log: 16 epoch (43648 / 60000 train. data). Loss: 0.06470851600170135\n",
            "Training log: 16 epoch (44928 / 60000 train. data). Loss: 0.20737309753894806\n",
            "Training log: 16 epoch (46208 / 60000 train. data). Loss: 0.10091068595647812\n",
            "Training log: 16 epoch (47488 / 60000 train. data). Loss: 0.08126774430274963\n",
            "Training log: 16 epoch (48768 / 60000 train. data). Loss: 0.09044238179922104\n",
            "Training log: 16 epoch (50048 / 60000 train. data). Loss: 0.10938362032175064\n",
            "Training log: 16 epoch (51328 / 60000 train. data). Loss: 0.23256659507751465\n",
            "Training log: 16 epoch (52608 / 60000 train. data). Loss: 0.10765965282917023\n",
            "Training log: 16 epoch (53888 / 60000 train. data). Loss: 0.14093197882175446\n",
            "Training log: 16 epoch (55168 / 60000 train. data). Loss: 0.15329775214195251\n",
            "Training log: 16 epoch (56448 / 60000 train. data). Loss: 0.10999221354722977\n",
            "Training log: 16 epoch (57728 / 60000 train. data). Loss: 0.1628984808921814\n",
            "Training log: 16 epoch (59008 / 60000 train. data). Loss: 0.12174839526414871\n",
            "Test loss (avg): 0.25971805409640075, Accuracy: 0.9213\n",
            "Training log: 17 epoch (128 / 60000 train. data). Loss: 0.1257217526435852\n",
            "Training log: 17 epoch (1408 / 60000 train. data). Loss: 0.09299679845571518\n",
            "Training log: 17 epoch (2688 / 60000 train. data). Loss: 0.09018535912036896\n",
            "Training log: 17 epoch (3968 / 60000 train. data). Loss: 0.140766441822052\n",
            "Training log: 17 epoch (5248 / 60000 train. data). Loss: 0.12708352506160736\n",
            "Training log: 17 epoch (6528 / 60000 train. data). Loss: 0.04404931515455246\n",
            "Training log: 17 epoch (7808 / 60000 train. data). Loss: 0.14788314700126648\n",
            "Training log: 17 epoch (9088 / 60000 train. data). Loss: 0.05759599804878235\n",
            "Training log: 17 epoch (10368 / 60000 train. data). Loss: 0.09529954195022583\n",
            "Training log: 17 epoch (11648 / 60000 train. data). Loss: 0.12932324409484863\n",
            "Training log: 17 epoch (12928 / 60000 train. data). Loss: 0.10985783487558365\n",
            "Training log: 17 epoch (14208 / 60000 train. data). Loss: 0.10287069529294968\n",
            "Training log: 17 epoch (15488 / 60000 train. data). Loss: 0.12218434363603592\n",
            "Training log: 17 epoch (16768 / 60000 train. data). Loss: 0.08700396120548248\n",
            "Training log: 17 epoch (18048 / 60000 train. data). Loss: 0.07327292859554291\n",
            "Training log: 17 epoch (19328 / 60000 train. data). Loss: 0.21076390147209167\n",
            "Training log: 17 epoch (20608 / 60000 train. data). Loss: 0.15736018121242523\n",
            "Training log: 17 epoch (21888 / 60000 train. data). Loss: 0.20801562070846558\n",
            "Training log: 17 epoch (23168 / 60000 train. data). Loss: 0.11949645727872849\n",
            "Training log: 17 epoch (24448 / 60000 train. data). Loss: 0.07999524474143982\n",
            "Training log: 17 epoch (25728 / 60000 train. data). Loss: 0.09268112480640411\n",
            "Training log: 17 epoch (27008 / 60000 train. data). Loss: 0.17007307708263397\n",
            "Training log: 17 epoch (28288 / 60000 train. data). Loss: 0.07932267338037491\n",
            "Training log: 17 epoch (29568 / 60000 train. data). Loss: 0.1094101294875145\n",
            "Training log: 17 epoch (30848 / 60000 train. data). Loss: 0.11724261939525604\n",
            "Training log: 17 epoch (32128 / 60000 train. data). Loss: 0.12670797109603882\n",
            "Training log: 17 epoch (33408 / 60000 train. data). Loss: 0.2819017469882965\n",
            "Training log: 17 epoch (34688 / 60000 train. data). Loss: 0.12774254381656647\n",
            "Training log: 17 epoch (35968 / 60000 train. data). Loss: 0.20049868524074554\n",
            "Training log: 17 epoch (37248 / 60000 train. data). Loss: 0.04594951122999191\n",
            "Training log: 17 epoch (38528 / 60000 train. data). Loss: 0.06348305940628052\n",
            "Training log: 17 epoch (39808 / 60000 train. data). Loss: 0.09239182621240616\n",
            "Training log: 17 epoch (41088 / 60000 train. data). Loss: 0.10511059314012527\n",
            "Training log: 17 epoch (42368 / 60000 train. data). Loss: 0.08336105197668076\n",
            "Training log: 17 epoch (43648 / 60000 train. data). Loss: 0.06828167289495468\n",
            "Training log: 17 epoch (44928 / 60000 train. data). Loss: 0.09186743944883347\n",
            "Training log: 17 epoch (46208 / 60000 train. data). Loss: 0.059529393911361694\n",
            "Training log: 17 epoch (47488 / 60000 train. data). Loss: 0.09552507847547531\n",
            "Training log: 17 epoch (48768 / 60000 train. data). Loss: 0.09913129359483719\n",
            "Training log: 17 epoch (50048 / 60000 train. data). Loss: 0.0875478982925415\n",
            "Training log: 17 epoch (51328 / 60000 train. data). Loss: 0.09234654158353806\n",
            "Training log: 17 epoch (52608 / 60000 train. data). Loss: 0.14122730493545532\n",
            "Training log: 17 epoch (53888 / 60000 train. data). Loss: 0.0882551297545433\n",
            "Training log: 17 epoch (55168 / 60000 train. data). Loss: 0.14244413375854492\n",
            "Training log: 17 epoch (56448 / 60000 train. data). Loss: 0.09884435683488846\n",
            "Training log: 17 epoch (57728 / 60000 train. data). Loss: 0.05191411077976227\n",
            "Training log: 17 epoch (59008 / 60000 train. data). Loss: 0.12944264709949493\n",
            "Test loss (avg): 0.26050467603206634, Accuracy: 0.9225\n",
            "Training log: 18 epoch (128 / 60000 train. data). Loss: 0.09030377119779587\n",
            "Training log: 18 epoch (1408 / 60000 train. data). Loss: 0.12020441144704819\n",
            "Training log: 18 epoch (2688 / 60000 train. data). Loss: 0.07993703335523605\n",
            "Training log: 18 epoch (3968 / 60000 train. data). Loss: 0.12838114798069\n",
            "Training log: 18 epoch (5248 / 60000 train. data). Loss: 0.2018403261899948\n",
            "Training log: 18 epoch (6528 / 60000 train. data). Loss: 0.11040597409009933\n",
            "Training log: 18 epoch (7808 / 60000 train. data). Loss: 0.14260369539260864\n",
            "Training log: 18 epoch (9088 / 60000 train. data). Loss: 0.10849384218454361\n",
            "Training log: 18 epoch (10368 / 60000 train. data). Loss: 0.06272055953741074\n",
            "Training log: 18 epoch (11648 / 60000 train. data). Loss: 0.10259665548801422\n",
            "Training log: 18 epoch (12928 / 60000 train. data). Loss: 0.06999123096466064\n",
            "Training log: 18 epoch (14208 / 60000 train. data). Loss: 0.05698156729340553\n",
            "Training log: 18 epoch (15488 / 60000 train. data). Loss: 0.08257493376731873\n",
            "Training log: 18 epoch (16768 / 60000 train. data). Loss: 0.12021350860595703\n",
            "Training log: 18 epoch (18048 / 60000 train. data). Loss: 0.11457238346338272\n",
            "Training log: 18 epoch (19328 / 60000 train. data). Loss: 0.05795932933688164\n",
            "Training log: 18 epoch (20608 / 60000 train. data). Loss: 0.10451841354370117\n",
            "Training log: 18 epoch (21888 / 60000 train. data). Loss: 0.07358530908823013\n",
            "Training log: 18 epoch (23168 / 60000 train. data). Loss: 0.12302389740943909\n",
            "Training log: 18 epoch (24448 / 60000 train. data). Loss: 0.13476327061653137\n",
            "Training log: 18 epoch (25728 / 60000 train. data). Loss: 0.209487646818161\n",
            "Training log: 18 epoch (27008 / 60000 train. data). Loss: 0.10577166825532913\n",
            "Training log: 18 epoch (28288 / 60000 train. data). Loss: 0.11098452657461166\n",
            "Training log: 18 epoch (29568 / 60000 train. data). Loss: 0.08226314932107925\n",
            "Training log: 18 epoch (30848 / 60000 train. data). Loss: 0.14416354894638062\n",
            "Training log: 18 epoch (32128 / 60000 train. data). Loss: 0.06506425142288208\n",
            "Training log: 18 epoch (33408 / 60000 train. data). Loss: 0.08748738467693329\n",
            "Training log: 18 epoch (34688 / 60000 train. data). Loss: 0.11380612850189209\n",
            "Training log: 18 epoch (35968 / 60000 train. data). Loss: 0.07364694029092789\n",
            "Training log: 18 epoch (37248 / 60000 train. data). Loss: 0.1652900129556656\n",
            "Training log: 18 epoch (38528 / 60000 train. data). Loss: 0.11940067261457443\n",
            "Training log: 18 epoch (39808 / 60000 train. data). Loss: 0.09316122531890869\n",
            "Training log: 18 epoch (41088 / 60000 train. data). Loss: 0.1470293402671814\n",
            "Training log: 18 epoch (42368 / 60000 train. data). Loss: 0.12361893057823181\n",
            "Training log: 18 epoch (43648 / 60000 train. data). Loss: 0.0827965959906578\n",
            "Training log: 18 epoch (44928 / 60000 train. data). Loss: 0.1292390376329422\n",
            "Training log: 18 epoch (46208 / 60000 train. data). Loss: 0.12947101891040802\n",
            "Training log: 18 epoch (47488 / 60000 train. data). Loss: 0.07933972775936127\n",
            "Training log: 18 epoch (48768 / 60000 train. data). Loss: 0.11660069972276688\n",
            "Training log: 18 epoch (50048 / 60000 train. data). Loss: 0.11703702807426453\n",
            "Training log: 18 epoch (51328 / 60000 train. data). Loss: 0.08991088718175888\n",
            "Training log: 18 epoch (52608 / 60000 train. data). Loss: 0.10781551897525787\n",
            "Training log: 18 epoch (53888 / 60000 train. data). Loss: 0.11993706226348877\n",
            "Training log: 18 epoch (55168 / 60000 train. data). Loss: 0.1377633810043335\n",
            "Training log: 18 epoch (56448 / 60000 train. data). Loss: 0.09643839299678802\n",
            "Training log: 18 epoch (57728 / 60000 train. data). Loss: 0.07915651798248291\n",
            "Training log: 18 epoch (59008 / 60000 train. data). Loss: 0.09283864498138428\n",
            "Test loss (avg): 0.2584430652141571, Accuracy: 0.9216\n",
            "Training log: 19 epoch (128 / 60000 train. data). Loss: 0.1005566269159317\n",
            "Training log: 19 epoch (1408 / 60000 train. data). Loss: 0.10361183434724808\n",
            "Training log: 19 epoch (2688 / 60000 train. data). Loss: 0.08130879700183868\n",
            "Training log: 19 epoch (3968 / 60000 train. data). Loss: 0.11360788345336914\n",
            "Training log: 19 epoch (5248 / 60000 train. data). Loss: 0.12799416482448578\n",
            "Training log: 19 epoch (6528 / 60000 train. data). Loss: 0.16796419024467468\n",
            "Training log: 19 epoch (7808 / 60000 train. data). Loss: 0.09779345244169235\n",
            "Training log: 19 epoch (9088 / 60000 train. data). Loss: 0.06725926697254181\n",
            "Training log: 19 epoch (10368 / 60000 train. data). Loss: 0.08913525938987732\n",
            "Training log: 19 epoch (11648 / 60000 train. data). Loss: 0.07468663901090622\n",
            "Training log: 19 epoch (12928 / 60000 train. data). Loss: 0.0811530128121376\n",
            "Training log: 19 epoch (14208 / 60000 train. data). Loss: 0.11419767141342163\n",
            "Training log: 19 epoch (15488 / 60000 train. data). Loss: 0.07545622438192368\n",
            "Training log: 19 epoch (16768 / 60000 train. data). Loss: 0.04906173795461655\n",
            "Training log: 19 epoch (18048 / 60000 train. data). Loss: 0.14735540747642517\n",
            "Training log: 19 epoch (19328 / 60000 train. data). Loss: 0.09681752324104309\n",
            "Training log: 19 epoch (20608 / 60000 train. data). Loss: 0.05125802010297775\n",
            "Training log: 19 epoch (21888 / 60000 train. data). Loss: 0.057387180626392365\n",
            "Training log: 19 epoch (23168 / 60000 train. data). Loss: 0.15005792677402496\n",
            "Training log: 19 epoch (24448 / 60000 train. data). Loss: 0.16575758159160614\n",
            "Training log: 19 epoch (25728 / 60000 train. data). Loss: 0.10784689337015152\n",
            "Training log: 19 epoch (27008 / 60000 train. data). Loss: 0.1001194640994072\n",
            "Training log: 19 epoch (28288 / 60000 train. data). Loss: 0.08959672600030899\n",
            "Training log: 19 epoch (29568 / 60000 train. data). Loss: 0.1162952408194542\n",
            "Training log: 19 epoch (30848 / 60000 train. data). Loss: 0.13222134113311768\n",
            "Training log: 19 epoch (32128 / 60000 train. data). Loss: 0.12206601351499557\n",
            "Training log: 19 epoch (33408 / 60000 train. data). Loss: 0.06627954542636871\n",
            "Training log: 19 epoch (34688 / 60000 train. data). Loss: 0.15799838304519653\n",
            "Training log: 19 epoch (35968 / 60000 train. data). Loss: 0.0879114493727684\n",
            "Training log: 19 epoch (37248 / 60000 train. data). Loss: 0.12483147531747818\n",
            "Training log: 19 epoch (38528 / 60000 train. data). Loss: 0.12198256701231003\n",
            "Training log: 19 epoch (39808 / 60000 train. data). Loss: 0.08375772088766098\n",
            "Training log: 19 epoch (41088 / 60000 train. data). Loss: 0.12318000197410583\n",
            "Training log: 19 epoch (42368 / 60000 train. data). Loss: 0.056163009256124496\n",
            "Training log: 19 epoch (43648 / 60000 train. data). Loss: 0.08376844227313995\n",
            "Training log: 19 epoch (44928 / 60000 train. data). Loss: 0.17623543739318848\n",
            "Training log: 19 epoch (46208 / 60000 train. data). Loss: 0.08381497859954834\n",
            "Training log: 19 epoch (47488 / 60000 train. data). Loss: 0.14740659296512604\n",
            "Training log: 19 epoch (48768 / 60000 train. data). Loss: 0.07467085868120193\n",
            "Training log: 19 epoch (50048 / 60000 train. data). Loss: 0.11874166876077652\n",
            "Training log: 19 epoch (51328 / 60000 train. data). Loss: 0.08785650134086609\n",
            "Training log: 19 epoch (52608 / 60000 train. data). Loss: 0.13374391198158264\n",
            "Training log: 19 epoch (53888 / 60000 train. data). Loss: 0.10965518653392792\n",
            "Training log: 19 epoch (55168 / 60000 train. data). Loss: 0.11051079630851746\n",
            "Training log: 19 epoch (56448 / 60000 train. data). Loss: 0.07288134098052979\n",
            "Training log: 19 epoch (57728 / 60000 train. data). Loss: 0.15101182460784912\n",
            "Training log: 19 epoch (59008 / 60000 train. data). Loss: 0.18387055397033691\n",
            "Test loss (avg): 0.27717393649816513, Accuracy: 0.9208\n",
            "Training log: 20 epoch (128 / 60000 train. data). Loss: 0.10849649459123611\n",
            "Training log: 20 epoch (1408 / 60000 train. data). Loss: 0.0974806398153305\n",
            "Training log: 20 epoch (2688 / 60000 train. data). Loss: 0.06586386263370514\n",
            "Training log: 20 epoch (3968 / 60000 train. data). Loss: 0.06285816431045532\n",
            "Training log: 20 epoch (5248 / 60000 train. data). Loss: 0.1195976510643959\n",
            "Training log: 20 epoch (6528 / 60000 train. data). Loss: 0.07809697836637497\n",
            "Training log: 20 epoch (7808 / 60000 train. data). Loss: 0.0670604407787323\n",
            "Training log: 20 epoch (9088 / 60000 train. data). Loss: 0.11927333474159241\n",
            "Training log: 20 epoch (10368 / 60000 train. data). Loss: 0.115855373442173\n",
            "Training log: 20 epoch (11648 / 60000 train. data). Loss: 0.12056978046894073\n",
            "Training log: 20 epoch (12928 / 60000 train. data). Loss: 0.042356982827186584\n",
            "Training log: 20 epoch (14208 / 60000 train. data). Loss: 0.02792336605489254\n",
            "Training log: 20 epoch (15488 / 60000 train. data). Loss: 0.09155018627643585\n",
            "Training log: 20 epoch (16768 / 60000 train. data). Loss: 0.15341897308826447\n",
            "Training log: 20 epoch (18048 / 60000 train. data). Loss: 0.1261947900056839\n",
            "Training log: 20 epoch (19328 / 60000 train. data). Loss: 0.16903726756572723\n",
            "Training log: 20 epoch (20608 / 60000 train. data). Loss: 0.024653267115354538\n",
            "Training log: 20 epoch (21888 / 60000 train. data). Loss: 0.08032302558422089\n",
            "Training log: 20 epoch (23168 / 60000 train. data). Loss: 0.07682076841592789\n",
            "Training log: 20 epoch (24448 / 60000 train. data). Loss: 0.15359251201152802\n",
            "Training log: 20 epoch (25728 / 60000 train. data). Loss: 0.11495032906532288\n",
            "Training log: 20 epoch (27008 / 60000 train. data). Loss: 0.14204619824886322\n",
            "Training log: 20 epoch (28288 / 60000 train. data). Loss: 0.11714719235897064\n",
            "Training log: 20 epoch (29568 / 60000 train. data). Loss: 0.0785050317645073\n",
            "Training log: 20 epoch (30848 / 60000 train. data). Loss: 0.03745577484369278\n",
            "Training log: 20 epoch (32128 / 60000 train. data). Loss: 0.13435973227024078\n",
            "Training log: 20 epoch (33408 / 60000 train. data). Loss: 0.16418935358524323\n",
            "Training log: 20 epoch (34688 / 60000 train. data). Loss: 0.08918657898902893\n",
            "Training log: 20 epoch (35968 / 60000 train. data). Loss: 0.19593515992164612\n",
            "Training log: 20 epoch (37248 / 60000 train. data). Loss: 0.07682860642671585\n",
            "Training log: 20 epoch (38528 / 60000 train. data). Loss: 0.14311301708221436\n",
            "Training log: 20 epoch (39808 / 60000 train. data). Loss: 0.05467807129025459\n",
            "Training log: 20 epoch (41088 / 60000 train. data). Loss: 0.19370333850383759\n",
            "Training log: 20 epoch (42368 / 60000 train. data). Loss: 0.039110373705625534\n",
            "Training log: 20 epoch (43648 / 60000 train. data). Loss: 0.09420650452375412\n",
            "Training log: 20 epoch (44928 / 60000 train. data). Loss: 0.06397534906864166\n",
            "Training log: 20 epoch (46208 / 60000 train. data). Loss: 0.20961280167102814\n",
            "Training log: 20 epoch (47488 / 60000 train. data). Loss: 0.08148465305566788\n",
            "Training log: 20 epoch (48768 / 60000 train. data). Loss: 0.12390382587909698\n",
            "Training log: 20 epoch (50048 / 60000 train. data). Loss: 0.07968911528587341\n",
            "Training log: 20 epoch (51328 / 60000 train. data). Loss: 0.08806613832712173\n",
            "Training log: 20 epoch (52608 / 60000 train. data). Loss: 0.06521546095609665\n",
            "Training log: 20 epoch (53888 / 60000 train. data). Loss: 0.08692005276679993\n",
            "Training log: 20 epoch (55168 / 60000 train. data). Loss: 0.07098310440778732\n",
            "Training log: 20 epoch (56448 / 60000 train. data). Loss: 0.1495875120162964\n",
            "Training log: 20 epoch (57728 / 60000 train. data). Loss: 0.17424142360687256\n",
            "Training log: 20 epoch (59008 / 60000 train. data). Loss: 0.13373243808746338\n",
            "Test loss (avg): 0.2590707482237369, Accuracy: 0.9235\n",
            "{'train_loss': [tensor(0.3127, device='cuda:0', grad_fn=<NllLossBackward0>), tensor(0.4149, device='cuda:0', grad_fn=<NllLossBackward0>), tensor(0.2500, device='cuda:0', grad_fn=<NllLossBackward0>), tensor(0.2457, device='cuda:0', grad_fn=<NllLossBackward0>), tensor(0.2321, device='cuda:0', grad_fn=<NllLossBackward0>), tensor(0.2694, device='cuda:0', grad_fn=<NllLossBackward0>), tensor(0.1250, device='cuda:0', grad_fn=<NllLossBackward0>), tensor(0.3077, device='cuda:0', grad_fn=<NllLossBackward0>), tensor(0.1614, device='cuda:0', grad_fn=<NllLossBackward0>), tensor(0.1680, device='cuda:0', grad_fn=<NllLossBackward0>), tensor(0.1759, device='cuda:0', grad_fn=<NllLossBackward0>), tensor(0.1775, device='cuda:0', grad_fn=<NllLossBackward0>), tensor(0.1471, device='cuda:0', grad_fn=<NllLossBackward0>), tensor(0.2400, device='cuda:0', grad_fn=<NllLossBackward0>), tensor(0.1591, device='cuda:0', grad_fn=<NllLossBackward0>), tensor(0.0522, device='cuda:0', grad_fn=<NllLossBackward0>), tensor(0.1477, device='cuda:0', grad_fn=<NllLossBackward0>), tensor(0.1523, device='cuda:0', grad_fn=<NllLossBackward0>), tensor(0.0846, device='cuda:0', grad_fn=<NllLossBackward0>), tensor(0.0758, device='cuda:0', grad_fn=<NllLossBackward0>)], 'test_loss': [0.38413303890228273, 0.33417674460411073, 0.2999800678253174, 0.28694864380359647, 0.2749035228729248, 0.2669897354602814, 0.2584749703168869, 0.2511020880937576, 0.24553310277462007, 0.24944661436080934, 0.2500010194659233, 0.2488769595146179, 0.25329789714813233, 0.2532062297821045, 0.24398050694465637, 0.25971805409640075, 0.26050467603206634, 0.2584430652141571, 0.27717393649816513, 0.2590707482237369], 'test_acc': [0.86, 0.8782, 0.8902, 0.8919, 0.898, 0.9015, 0.9061, 0.9087, 0.9122, 0.9151, 0.9134, 0.9159, 0.9151, 0.9172, 0.921, 0.9213, 0.9225, 0.9216, 0.9208, 0.9235]}\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ],
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAiwAAAHHCAYAAACcHAM1AAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjcuMSwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy/bCgiHAAAACXBIWXMAAA9hAAAPYQGoP6dpAABW/ElEQVR4nO3deVxU5f4H8M/MwAzDNsi+KogKLgiISi5ldklSIzUzl3JNzdIWaXPXMuX26+alzLR7UzPNMhO1q6UppaWiJljuCIKCyK7sss08vz+QqQlQBoEZ4PN+veYVnHnOme/xNJ6P53nOcyRCCAEiIiIiIyY1dAFERERE98LAQkREREaPgYWIiIiMHgMLERERGT0GFiIiIjJ6DCxERERk9BhYiIiIyOgxsBAREZHRY2AhIiIio8fAQkREREaPgYWoFTl27BiWLVuGvLy8Jv2clStXYteuXU36GUREf8XAQtSKHDt2DG+//TYDCxG1OgwsRER/UVxcbOgSiKgWDCxErcSyZcvwxhtvAAC8vLwgkUggkUhw9epVbZstW7YgKCgISqUStra2GDduHFJTU3W2k5CQgNGjR8PZ2RlmZmZwd3fHuHHjkJ+fDwCQSCQoLi7Gpk2btJ8xZcqUOusqLy/HkiVLEBQUBJVKBQsLCzz44IP4+eefa7TVaDT48MMP4efnBzMzMzg4OOCxxx7DqVOndNpt2bIFffv2hbm5Odq1a4eHHnoIP/74o/Z9iUSCZcuW1di+p6enTq2ff/45JBIJDh8+jBdffBGOjo5wd3cHAFy7dg0vvvgifHx8oFQqYWdnhzFjxuj8eVbLy8vD3Llz4enpCYVCAXd3d0yaNAk5OTkoKiqChYUFXnnllRrrXb9+HTKZDBEREXX++RFRFRNDF0BEjePJJ5/E5cuX8dVXX+Hf//437O3tAQAODg4AgBUrVmDx4sV4+umnMX36dGRnZ2P16tV46KGHcPr0adjY2KC8vByhoaEoKyvDSy+9BGdnZ6SlpWHPnj3Iy8uDSqXC5s2bMX36dPTt2xczZ84EAHh7e9dZV0FBAT777DOMHz8eM2bMQGFhIdavX4/Q0FCcPHkSAQEB2rbPPfccPv/8cwwdOhTTp09HZWUlfv31Vxw/fhy9e/cGALz99ttYtmwZ+vfvj3feeQdyuRwnTpzATz/9hCFDhjToz+7FF1+Eg4MDlixZor3C8ttvv+HYsWMYN24c3N3dcfXqVaxduxYPP/wwLly4AHNzcwBAUVERHnzwQVy8eBHTpk1Dr169kJOTg++++w7Xr19HQEAARo0ahW3btmHVqlWQyWTaz/3qq68ghMAzzzzToLqJ2hRBRK3G+++/LwCI5ORkneVXr14VMplMrFixQmf52bNnhYmJiXb56dOnBQCxffv2u36OhYWFmDx5cr1qqqysFGVlZTrLbt26JZycnMS0adO0y3766ScBQLz88ss1tqHRaIQQQiQkJAipVCpGjRol1Gp1rW2EEAKAWLp0aY3tdOjQQafujRs3CgBi4MCBorKyUqdtSUlJjfVjYmIEAPHFF19oly1ZskQAEFFRUXXWvX//fgFA/PDDDzrv9+zZUwwaNKjGekRUE7uEiNqAqKgoaDQaPP3008jJydG+nJ2d0blzZ233jEqlAgDs378fJSUljfLZMpkMcrkcQFWXz82bN1FZWYnevXsjLi5O227Hjh2QSCRYunRpjW1IJBIAwK5du6DRaLBkyRJIpdJa2zTEjBkzdK58AIBSqdT+XFFRgdzcXHTq1Ak2NjY16vb398eoUaPqrDskJASurq748ssvte+dO3cOZ86cwbPPPtvguonaEgYWojYgISEBQgh07twZDg4OOq+LFy8iKysLQNXYl/DwcHz22Wewt7dHaGgo1qxZox2/0lCbNm1Cz549YWZmBjs7Ozg4OGDv3r06271y5QpcXV1ha2tb53auXLkCqVSKbt263Vc9f+fl5VVj2e3bt7FkyRJ4eHhAoVDA3t4eDg4OyMvLq1F3jx497rp9qVSKZ555Brt27dIGwS+//BJmZmYYM2ZMo+4LUWvFMSxEbYBGo4FEIsEPP/xQ40oCAFhaWmp//uCDDzBlyhTs3r0bP/74I15++WVERETg+PHj2gGp+tiyZQumTJmCkSNH4o033oCjo6N2oOmVK1fua7/0pVara13+16sp1V566SVs3LgRr776Kvr16weVSgWJRIJx48ZBo9Ho/dmTJk3C+++/j127dmH8+PHYunUrHn/8ce1VLSK6OwYWolakrm4Rb29vCCHg5eWFLl263HM7fn5+8PPzw6JFi3Ds2DEMGDAA69atw7vvvnvXz6nNt99+i44dOyIqKkpnvb93/Xh7e2P//v24efNmnVdZvL29odFocOHCBZ3Bun/Xrl27GnPRlJeXIz09Xa+6J0+ejA8++EC7rLS0tMZ2vb29ce7cuXtur0ePHggMDMSXX34Jd3d3pKSkYPXq1fWuh6itY5cQUStiYWEBADVOqk8++SRkMhnefvttCCF03hNCIDc3F0DVHT2VlZU67/v5+UEqlaKsrEznc+o7OV31FZ2/fu6JEycQExOj02706NEQQuDtt9+usY3qdUeOHAmpVIp33nmnxlWOv27f29sbv/zyi877//nPf+q8wlJX3X//s1q9enWNbYwePRp//PEHdu7cWWfd1SZOnIgff/wRkZGRsLOzw9ChQ+tdD1FbxyssRK1IUFAQAGDhwoUYN24cTE1NERYWBm9vb7z77ruYP38+rl69ipEjR8LKygrJycnYuXMnZs6ciddffx0//fQT5syZgzFjxqBLly6orKzE5s2bIZPJMHr0aJ3POXjwIFatWgVXV1d4eXkhODi41poef/xxREVFYdSoURg+fDiSk5Oxbt06dOvWDUVFRdp2gwcPxsSJE/HRRx8hISEBjz32GDQaDX799VcMHjwYc+bMQadOnbBw4UIsX74cDz74IJ588kkoFAr89ttvcHV11c5nMn36dMyaNQujR4/Go48+ij/++AP79+/X3updH48//jg2b94MlUqFbt26ISYmBgcPHoSdnZ1OuzfeeAPffvstxowZg2nTpiEoKAg3b97Ed999h3Xr1sHf31/bdsKECXjzzTexc+dOvPDCCzA1Na13PURtnqFuTyKiprF8+XLh5uYmpFJpjVucd+zYIQYOHCgsLCyEhYWF8PX1FbNnzxbx8fFCCCGSkpLEtGnThLe3tzAzMxO2trZi8ODB4uDBgzqfcenSJfHQQw8JpVIpANz1FmeNRiNWrlwpOnToIBQKhQgMDBR79uwRkydPFh06dNBpW1lZKd5//33h6+sr5HK5cHBwEEOHDhWxsbE67TZs2CACAwOFQqEQ7dq1E4MGDRIHDhzQvq9Wq8Vbb70l7O3thbm5uQgNDRWJiYl13tb822+/1aj71q1bYurUqcLe3l5YWlqK0NBQcenSpRrbEEKI3NxcMWfOHOHm5ibkcrlwd3cXkydPFjk5OTW2O2zYMAFAHDt2rM4/MyKqSSLE365ZEhFRkxk1ahTOnj2LxMREQ5dC1KJwDAsRUTNJT0/H3r17MXHiREOXQtTicAwLEVETS05OxtGjR/HZZ5/B1NQUzz//vKFLImpxeIWFiKiJHT58GBMnTkRycjI2bdoEZ2dnQ5dE1OJwDAsREREZPV5hISIiIqPHwEJERERGr9UMutVoNLhx4wasrKzu66mtRERE1HyEECgsLISrq2uNp7D/VasJLDdu3ICHh4ehyyAiIqIGSE1NvesDVltNYLGysgJQtcPW1tYGroaIiIjqo6CgAB4eHtrzeF1aTWCp7gaytrZmYCEiImph7jWcg4NuiYiIyOgxsBAREZHRY2AhIiIio8fAQkREREaPgYWIiIiMHgMLERERGT0GFiIiIjJ6DCxERERk9BhYiIiIyOgxsBAREZHRY2AhIiIio8fAQkREREaPgYWIiIjuqqC0AieTbxq0hlbztGYiIiJqXEII7DydhpXfX0J5pRo/v/4w7CwVBqmFgYWIiIhquJRRgMW7zuG3q7cAAB0dLJBVWMbAQkRERIZXWFqBfx9IwKaYq1BrBJSmMrz8j854bqAX5CaGG0nCwEJEREQQQmD37zew4vuLyC4sAwAM7eGMRY93g5uN0sDVMbAQERG1efEZhVi8+5x2YK2XvQWWPdEdg7o4GLiyPzGwEBFRm1Wh1uB0Sh6OJObgeFIuFCZS+Lmp0NNdhR5uKrjZKCGRSAxdZpMpKqvEhwcvY8PRqu4fM1MpXnqkM6Y/6AWFiczQ5elgYCEiojZDCIGErCIcScjBkcQcnEjKRXG5WqfNrwk52p9tLeTo4aaCn5s1/Nxs4OeugqvKrMWHGCEE/ncmHSv2XkBmQVX3T2h3Jyx+vBvc25kbuLraMbAQEVGrlllQiqOJOdqQknVnfEY1Wws5BnSyx8BOdqjUCJy9no+zafmIzyjEzeJy/HI5G79cztZp7+emqnq5V/3XpQWFmITMQizZfR4xSbkAgA525lj2RHcM9nE0cGV3x8BCREStSlFZJU4m5+LXhBwcTczB5cwinfcVJlL09bLFwE72GNjZHl2drSGV/iVsBFf9p7RCjfiMQpxNy9eGmMuZVSHm8OVsHP5LiLGzkGvDS487XUrO1sYVYorLKvFRdALWH0lGpUZAYSLF7MGdMPOhjjAzNa7un9pIhBDC0EU0hoKCAqhUKuTn58Pa2trQ5RARUTOpVGvwx/V8HLkTUOJSbqFS8+epTSIB/NxUGNDJHg92skevDu0afIIurVDjkjbE5OFsWgEuZxZCral5KrW3/PNKTFWIsYGTtaLZQ4wQAnvPpuPdPReRUVAKAAjp6oSlYd3gYWv47p/6nr8ZWIiIqEURQiApp1jbxXP8Si4Kyyp12rS3Na8KKJ3t0a+jHdpZyJusntIKNS6mF+BcWj7O3LkSk5BVVGuIaWduCl9na/g4W6GrixV8na3RxckKSnnTXOFIzCrCsu/O40hi1bgcD1slloV1xz+6OjXJ5zUEAwsREbU4QgjcrlAj/3ZF1auk4s+fb1cgPqMQRxNzcCO/VGc9ldIUAzrZYWAnBwzsZI/2doa9clBaocaFv4SYc3cJMRIJ4GlnAV9nK/g4V4WYri5W8GhnrttVpYeS8kqs/ikRn/2ahAq1gNxEihcf9sasQd5G1/3DwEJERAYhhEBphUYbMvJKynVCR8Ft3RDy91eF+t6nJblMit6e7TCwsz0GdrJHd1cVZA08uTeX0go1ErOKcDG9APEZhbiUUYhLGQXIKSqvtb25XIYuTlbwdb7zcrGGr7MVbMzrvlokhMC+cxlYvueCNtQ94uuIpWHd0MHOokn2634xsBARUbMRQmD9kWSsP5KM3KJylKs197U9mVQCG6UpVEpTWN/5r0ppClcbJfp726GPp22TdaM0t+zCsjsBpgAX0wsRn1mAy5lFKK+s/c/Q2doMvi5VV2O6OlvD18UKHe0tcf1WCZZ+d157W7Z7u6run5BuxtP9UxsGFiIiahbllRos2nUW35y6rrNcJpXA2swENuZyndChUppof7ZR/u0986r/WshlRnWHTXOrVGtwNbe46ipM+p9XY67ful1re5M7V5cqNQJymRSzBnXECw93ahGhrr7n7wbd1rxmzRq8//77yMjIgL+/P1avXo2+ffvW2raiogIRERHYtGkT0tLS4OPjg/feew+PPfaYtk1ERASioqJw6dIlKJVK9O/fH++99x58fHwaUh4RETWTvJJyzNoSi+NJNyGVAAuGdcVjPZyhUprCUmHSpkPH/TCRSdHJ0QqdHK3weM8/lxeWVuByZiEuplcFmPg7gaZ60PGgLg54+4nu8LQ3zu6f+6F3YNm2bRvCw8Oxbt06BAcHIzIyEqGhoYiPj4ejY81JZxYtWoQtW7bgv//9L3x9fbF//36MGjUKx44dQ2BgIADg8OHDmD17Nvr06YPKykosWLAAQ4YMwYULF2Bh0fr+0ImIWoOk7CI8t+kUknOKYakwwerxgRjsa9yTj7V0VmamCOpgi6AOttplQgik5d1GaYUa3g6WrTYk6t0lFBwcjD59+uDjjz8GAGg0Gnh4eOCll17CvHnzarR3dXXFwoULMXv2bO2y0aNHQ6lUYsuWLbV+RnZ2NhwdHXH48GE89NBD9aqLXUJERM0n5kouZm2JRf7tCrjZKLF+Sm/4OvPvXtJfk3QJlZeXIzY2FvPnz9cuk0qlCAkJQUxMTK3rlJWVwczMTGeZUqnEkSNH6vyc/Px8AICtrW2dbcrKylBW9uf0ygUFBfXaByIiuj/f/JaKBTvPolIjEOBhg/9O6g0HK4Why6JWTqpP45ycHKjVajg56Y44dnJyQkZGRq3rhIaGYtWqVUhISIBGo8GBAwcQFRWF9PT0WttrNBq8+uqrGDBgAHr06FFnLREREVCpVNqXh4eHPrtCRER60mgEIn64iDd3nEGlRuDxni74euYDDCvULPQKLA3x4YcfonPnzvD19YVcLsecOXMwdepUSKW1f/Ts2bNx7tw5fP3113fd7vz585Gfn699paamNkX5RESEqonIXvgyFp8eTgIAvPxIJ3w0LtDoJiGj1kuvLiF7e3vIZDJkZmbqLM/MzISzs3Ot6zg4OGDXrl0oLS1Fbm4uXF1dMW/ePHTs2LFG2zlz5mDPnj345Zdf4O7uftdaFAoFFAqmeiKippZZUIrpm07hbFo+5DIp3nvKD6MC7/53NFFj0+sKi1wuR1BQEKKjo7XLNBoNoqOj0a9fv7uua2ZmBjc3N1RWVmLHjh0YMWKE9j0hBObMmYOdO3fip59+gpeXl567QURETeFcWj5GfHwUZ9PyYWshx9YZwQwrZBB639YcHh6OyZMno3fv3ujbty8iIyNRXFyMqVOnAgAmTZoENzc3REREAABOnDiBtLQ0BAQEIC0tDcuWLYNGo8Gbb76p3ebs2bOxdetW7N69G1ZWVtrxMCqVCkqlsjH2k4iI9HTgQiZe+fo0SsrV6ORoiQ2T+xj8GT3UdukdWMaOHYvs7GwsWbIEGRkZCAgIwL59+7QDcVNSUnTGp5SWlmLRokVISkqCpaUlhg0bhs2bN8PGxkbbZu3atQCAhx9+WOezNm7ciClTpui/V0RE1GBCCHz2azJW/nARQgAPdrbHxxN6QaU0NXRp1IZxan4iItKqUGuwZPd5fHUyBQDwTHB7LHuiO0xlTX6PBrVRTTo1PxERtT75JRV4cWssjibmQiIBFg3vhmkDPFvtzKnUsjCwEBERruUWY+rnvyEpuxgWchk+Gh+If3Q17qf8UtvCwEJE1MadTL6J5zefwq2SCriqzLB+Sh90dWHXOhkXBhYiojZsR+x1zIs6gwq1gL+7Cv+d1BuO1mb3XpGomTGwEBG1QRqNwKoDl/Hxz4kAgGF+zvhgTACUcs5cS8aJgYWIqI0prVDjtW/+wN6zVc90mz3YG6896gOplINryXgxsBARtSFZhaWY8UUs/kjNg6lMgn8+2ROjgzhzLRk/BhYiojagUq3B3rPpeO+HS7iRX4p25qb4dGJv9PWyNXRpRPXCwEJE1IqVVqix/VQq/vNrElJv3gYAdHSwwIbJfeBpb2Hg6ojqj4GFiKgVyr9dgS3Hr2HDkWTkFpcDAOws5Jg6wBOT+3vCyozT7FPLwsBCRNSKZBaUYv2RZGw9kYKiskoAgHs7JZ5/qCPG9PaAmSnvAqKWiYGFiKgVSMouwn9+SUJUXBrK1RoAgK+zFV542BvD/VxgwmcBUQvHwEJE1IKduZ6HdYev4IdzGah+lG1fL1u8MMgbD/s48DlA1GowsBARtTBCCBxNzMXaw4k4mpirXR7S1QkvPNwRQR145w+1PgwsRET1dDWnGB8cuIzzafno6GAJX2cr+LpYwdfZGp525k3e7aLWCOw/n4G1h67gbFo+AMBEKsETAa6YNcgbXZysmvTziQyJgYWI6B7ySsrxUXQiNh+/igp1Vb9LUk4xDl7M1LaRm0jRxckSvs7WVUHG2Rq+Llawt1Tc9+eXVaoRFZeG//yShOScYgCA0lSGsX08MP1BL7i3M7/vzyAydgwsRER1KKtUY3PMNXwUnYCC0qo7bgZ1ccDEBzrg+q0SXMooxKWMQsRnFOJ2hRrn0gpwLq1AZxv2lnJtiPFxtkJXF2t0crSs1906haUV2HoiBeuPJCOrsAwAoFKaYkr/qluTbS3kjb/TREaKgYWI6G+EEPjhXAb++cMlpNwsAVB1x82CYV3xUBeHGu01GoGUm9UBpgCX0gsRn1mIq7nFyCkqx5HEHBxJzNG2l0kl8LQzh6+LNbo6W8HnTqBxb6eERCJBdmEZNh5Nxubj11B4Jyi5qMww/cGOGNfHAxYK/tVNbY9EiOpx5S1bQUEBVCoV8vPzYW1tbehyiKgOqTdLsO7wFbS3NceoXm5wtDIzdEk64lJuYcXei4i9dgsA4GClwOtDuuCpIA/I9Hw4YEl5JS5nFiE+owAX0++EmYxC5JVU1NreSmECb0dLXEwvQFll1a3J3g4WmDXIGyMC3CA34a3J1PrU9/zNwEJEzUKtEdh07Cr+9WM8SsrVAKquNDzcxQFjervjEV8ng56QU2+W4L19l7DnTNUTjJWmMsx8qCNmPtSxUa9oCCGQVViGi+kFiL/TpXQxvQBXsou042MAIMDDBi887I1HuzrxKcrUqjGwEJHRSMgsxJs7zuB0Sh4AIKhDO2iE0P4OALYWcowIcMWYIA90c22+73D+7Qqs+TkRnx+9inK1BhIJ8FQvd7w2xAfOqua7+lOh1iApuxiXMwvhamOGXu3bcQ4VahMYWIjI4MorNVh76Ao+/jkBFWoBS4UJ5g31xYS+7SGVSpCYVYjtsdcRFZeG7DuDSgGgu6s1xgS5Y0SAG9o10cDSCrUGXx6/hg+jE3DrThfNgE52WDCsK7q7qprkM4moJgYWIjKo31Pz8Na3ZxCfWQgA+IevI94d1QMuKmWNtpVqDX5JyMb2U9dx8GKmtmtELpMipJsjxgR54MHO9o0yz4kQAj9eyMQ/f7ikvUW4s6MlFgzryplhiQyAgYWIDKKkvBIf/HgZG48mQyOqunqWPdEdYT1d6hUGbhaXY/fvadh+6joupP95i7CTtQKjAt0xprc7vB0sG1Tbmet5eHfvRZxMvgmg6pbjuY92wdjeHnzWDpGBMLAQUbM7mpiDeVFnkHrzNgBgVKAbFj/ercHzhZy/kY/tp65j9+9p2m4boGoMzJggdwzv6QIrM9N7bict7zbe33cJu36/AQBQmEgx48GOeH5Qx3qtT0RNh4GFiJpNfkkFVnx/Ad+cug4AcFWZYcWTfhjs49go2y+rVOOni1nYHnsdh+KzoLnzt5aZqRTDerjgqd7ueMDLrsbdNIWlFVh76ArWH0nW3ib8ZKAbXg/1gatNza4pImp+DCxE1Cz2nUvH4t3ntYNmJ/XrgDcf84VlE01ullVQiqjTadh+KhVXsou1yz1slRjdyx2je7nDRWWGr35LReSBy8gtLgcAPNDRFouGd0MPNw6oJTImDCxE1KSyCkuxdPd5/HAuAwDQ0cEC743uiT6ezfOkYCEETqfmYfup69jzxw0UllVq33OwUmgDVEcHC8wf2hUhXR05oJbICDGwEFGTEEJge+x1vLvnAgpKK2EilWDWIG/MeaRTvZ6P0xRul6ux/3wGtsem4mhiLoCqwb6vhnTG+L7tYcoBtURGq77nbz6QgojqLSW3BAt2ntU+F8fPTYX3Rvds1oneaqOUyzAy0A0jA91w/VYJLtwowAPedrDmgFqiVoOBhYjuSa0R2Hg0GR/8eBm3K9RQmEgR/mgXPDfQy+huB3ZvZw73duaGLoOIGhkDCxHdVXxGId7acQa/p+YBqBq8+s8ne8LT3sKwhRFRm8LAQkS1KqtU45Ofr+CTQ4moUAtYKUywYHhXjO3twYfxEVGzY2AhohpOp9zCWzvO4HJmEQAgpKsT3h3Zo1kfBkhE9FcMLESkJYTAhqNXsfL7i1BrBOwtq6bVH+5Xv2n1iYiaCgMLEQEAissq8daOM9hzJh0A8HhPFywf0aPJnpZMRKQPBhYiwpXsIszaHIuErCKYSCVY/Hg3TOrXgVdViMhoMLAQtXE/nE3HG9+eQVFZJZysFfjkmV4I6tA8s9USEdUXAwtRG1Wp1uD9/fH49JckAECwly1WTwiEoxUH1hKR8WFgIWqDsgvL8NJXcTiedBMAMPOhjngz1MfoJoEjIqrGwELUxsReu4XZX8Yho6AUFnIZ3h/jj2F+LoYui4jorhhYiNoIIQQ2H7+G5XsuoEIt0MnREuue7YVOjlaGLo2I6J4adP13zZo18PT0hJmZGYKDg3Hy5Mk621ZUVOCdd96Bt7c3zMzM4O/vj3379um0+eWXXxAWFgZXV1dIJBLs2rWrIWURUR1ul6sR/s0fWLL7PCrUAsP9XLBr9gCGFSJqMfQOLNu2bUN4eDiWLl2KuLg4+Pv7IzQ0FFlZWbW2X7RoET799FOsXr0aFy5cwKxZszBq1CicPn1a26a4uBj+/v5Ys2ZNw/eEiGp1NacYoz45ip2n0yCTSrBoeFd8PCEQlgpeYCWilkMihBD6rBAcHIw+ffrg448/BgBoNBp4eHjgpZdewrx582q0d3V1xcKFCzF79mztstGjR0OpVGLLli01C5JIsHPnTowcOVKvHSkoKIBKpUJ+fj6srQ37qHsiY3HwQibmfvM7CksrYW+pwJoJgQjuaGfosoiItOp7/tbrn1jl5eWIjY3F/PnztcukUilCQkIQExNT6zplZWUwM9O9TVKpVOLIkSP6fHSt2y0rK9P+XlBQcF/bI2pN1BqBfx+4jI9/TgQABHVoh0+e6QUna96yTEQtk15dQjk5OVCr1XByctJZ7uTkhIyMjFrXCQ0NxapVq5CQkACNRoMDBw4gKioK6enpDa8aQEREBFQqlfbl4eFxX9sjai1uFpdjysaT2rAypb8nvprxAMMKEbVoTT7pwocffojOnTvD19cXcrkcc+bMwdSpUyGV3t9Hz58/H/n5+dpXampqI1VM1HL9kZqHsNVH8GtCDpSmMnw4LgDLnugOuQnnVyGilk2vLiF7e3vIZDJkZmbqLM/MzISzs3Ot6zg4OGDXrl0oLS1Fbm4uXF1dMW/ePHTs2LHhVQNQKBRQKBT3tQ2i1kIIga9/S8XS3edRrtbAy94C654Ngo8z7wIiotZBr392yeVyBAUFITo6WrtMo9EgOjoa/fr1u+u6ZmZmcHNzQ2VlJXbs2IERI0Y0rGIi0lFaocZbO85gftRZlKs1eLSbE3bPGcCwQkStit73NYaHh2Py5Mno3bs3+vbti8jISBQXF2Pq1KkAgEmTJsHNzQ0REREAgBMnTiAtLQ0BAQFIS0vDsmXLoNFo8Oabb2q3WVRUhMTERO3vycnJ+P3332Fra4v27dvf7z4StVqpN0swa0sszt8ogFQCvB7qg1kPeUMq5VOWiah10TuwjB07FtnZ2ViyZAkyMjIQEBCAffv2aQfipqSk6IxPKS0txaJFi5CUlARLS0sMGzYMmzdvho2NjbbNqVOnMHjwYO3v4eHhAIDJkyfj888/b+CuEbVuP8dn4dWvf0f+7QrYWsixenwgBnSyN3RZRERNQu95WIwV52GhtqKorBKroxPwn1+TIATg72GDtc/0gquN0tClERHprUnmYSEiw9FoBKJOp+G9fZeQXVg1B9Ezwe2xJKwbFCYyA1dHRNS0GFiIWoDTKbew7H8X8EdqHgCgg505Fg/vhpBuTndfkYiolWBgITJimQWleO+HS4g6nQYAsJDL8NI/OmPqAE9eVSGiNoWBhcgIlVaosf5IMtb8nIiScjUA4Kkgd7z5mA8crThjLRG1PQwsREZECIEfL2Rixd6LSLlZAgAIbG+DZWHd4e9hY9jiiIgMiIGFyEjEZxTinT3ncTQxFwDgZK3AvKG+GOHvxnlViKjNY2AhMrC8knL8+8BlbDmRArVGQG4ixYwHvfDiw51goeBXlIgIYGAhMphKtQZfnUzBBwcuI6+kAgDwWHdnLBjWFe3tzA1cHRGRcWFgITKAY1dy8M7/LuBSRiEAwMfJCkvCunGmWiKiOjCwEDWj1JslWLH3IvadzwAAqJSmeG1IF0zo2x4mMr2eRUpE1KYwsBA1g+KySqw9dAX/+TUJ5ZUayKQSPBvcHq+GdEE7C7mhyyMiMnoMLERNSAiB3b/fQMQPF5FZUDWdfn9vOywN6w4fZysDV0dE1HIwsBA1kTPX87Dsu/OIS8kDAHjYKrFoeDcM6eYEiYS3KRMR6YOBhagJrD+SjHf3XoAQgLlchtmDO+G5gV4wM+V0+kREDcHAQtTINh27iuV7LgAARgS4Yv7QrnBWcTp9IqL7wcBC1Ii2nkjB0u/OAwDmDO6E14Z0YfcPEVEj4H2URI3km1OpWLDzLADg+Yc6MqwQETUiBhaiRrDrdBre2nEGADB1gCfmDfVlWCEiakQMLET3ae+ZdIR/8zuEAJ59oD2WPN6NYYWIqJExsBDdh33nMvDy16ehEcDY3h5454keDCtERE2AgYWogaIvZuKlr+Kg1gg8GeiGlU/6QSplWCEiagoMLEQNcPhyNl7YEocKtUCYvyveH+MPGcMKEVGTYWAh0tOxxBzM/OIUytUaPNbdGaueZlghImpqDCxEejiZfBPPbTqFskoNQro64qPxgTDlU5aJiJoc/6YlqqfYa7cwdeNJ3K5QY1AXB6x5phfkJvwKERE1B/5tS1QPf6TmYcqGkyguV2NAJzt8OjEIChM+F4iIqLkwsBDdw7m0fExcfwKFZZUI9rLFZ5P68CGGRETNjIGF6C4uZRRg4voTKCitRFCHdtgwpQ+UcoYVIqLmxsBCVIfErEI8+9kJ3CqpgL+HDTZO7QMLBZ8XSkRkCAwsRLVIyi7C+P+eQE5RObq7WuOLqX1hbWZq6LKIiNosBhaiv0nJLcGE/55AdmEZfJ2tsOW5YKjMGVaIiAyJgYXoL67fKsH4/x5HRkEpOjtaYsv0YLSzkBu6LCKiNo+BheiO9PzbmPDfE0jLu42O9hb4ckYw7C0Vhi6LiIjAwEIEAMgqKMWE/55Ays0SdLAzx9YZD8DRyszQZRER0R0MLNTm5RSVYcJnJ5CcUww3GyW2zngAziqGFSIiY8LAQm3areJyPPvZCSRmFcFFZYavZjwANxulocsiIqK/YWChNiu/pALPrj+BSxmFcLRSYOuMB9DeztzQZRERUS0YWKhNyi4sw6QNJ3D+RgHsLeXYOuMBeNlbGLosIiKqA6ftpDYn9totzP4yDhkFpWhnboovpz+ATo6Whi6LiIjugoGF2gwhBDYfv4bley6gQi3g7WCBTycGoZOjlaFLIyKie2BgoTbhdrkaC3aexc7TaQCAYX7O+L+n/GHJZwMREbUI/NuaWr2rOcWYtSUWlzIKIZNKMH+oL54b6AWJRGLo0oiIqJ4aNOh2zZo18PT0hJmZGYKDg3Hy5Mk621ZUVOCdd96Bt7c3zMzM4O/vj3379t3XNonq6+CFTIR9fASXMgphbynHl9ODMf3BjgwrREQtjN6BZdu2bQgPD8fSpUsRFxcHf39/hIaGIisrq9b2ixYtwqefforVq1fjwoULmDVrFkaNGoXTp083eJtE96LWCPxrfzymf3EKhaWVCOrQDnteehAPdLQzdGlERNQAEiGE0GeF4OBg9OnTBx9//DEAQKPRwMPDAy+99BLmzZtXo72rqysWLlyI2bNna5eNHj0aSqUSW7ZsadA2a1NQUACVSoX8/HxYW1vrs0vUytwsLscrX5/Grwk5AIAp/T2xYFhXyE14Fz8RkbGp7/lbr7/By8vLERsbi5CQkD83IJUiJCQEMTExta5TVlYGMzPdac6VSiWOHDnS4G1Wb7egoEDnRXTmeh7CVh/Brwk5UJrK8OG4ACx7ojvDChFRC6fX3+I5OTlQq9VwcnLSWe7k5ISMjIxa1wkNDcWqVauQkJAAjUaDAwcOICoqCunp6Q3eJgBERERApVJpXx4eHvrsCrVCX59MwVNrY5CWdxuedubYObs/RgS4GbosIiJqBE3+z84PP/wQnTt3hq+vL+RyOebMmYOpU6dCKr2/j54/fz7y8/O1r9TU1EaqmFqa0go13vz2D8yLOotytQaPdnPCdy8NhK8zuwaJiFoLvW5rtre3h0wmQ2Zmps7yzMxMODs717qOg4MDdu3ahdLSUuTm5sLV1RXz5s1Dx44dG7xNAFAoFFAoFPqUT61Q6s0SvPBlLM6lFUAqAV4b4oMXBnlDKuVdQERErYlelznkcjmCgoIQHR2tXabRaBAdHY1+/frddV0zMzO4ubmhsrISO3bswIgRI+57m9S2HYrPQtjHR3AurQC2FnJ8MS0Yswd3YlghImqF9J44Ljw8HJMnT0bv3r3Rt29fREZGori4GFOnTgUATJo0CW5uboiIiAAAnDhxAmlpaQgICEBaWhqWLVsGjUaDN998s97bJPorjUbg458T8e+DlyEE4O+uwifPBsHNRmno0oiIqInoHVjGjh2L7OxsLFmyBBkZGQgICMC+ffu0g2ZTUlJ0xqeUlpZi0aJFSEpKgqWlJYYNG4bNmzfDxsam3tskqpZfUoG53/yOny5VzdEzIbg9loZ1g8JEZuDKiIioKek9D4ux4jwsrd/5G/l4YUscUm6WQGEixbsje2BMb94dRkTUktX3/M1nCVGLsCP2OhbsPIuySg08bJVY+0wQeripDF0WERE1EwYWMmpllWos33MBW46nAAAe9nFA5NgA2JjLDVwZERE1JwYWMlo38m7jhS/j8EdqHiQS4JV/dMbLj3TmXUBERG0QAwsZpZvF5Ri99hjS80uhUpoiclwABvs4GrosIiIyEAYWMjpCCLy+/Q+k55fC084cm58LhoetuaHLIiIiA+IT4cjobDh6FT9dyoLcRIpPngliWCEiIgYWMi5nr+fjnz9cBAAsHt4V3Vx5izoRETGwkBEpLK3AnK/iUKEWCO3uhGcf6GDokoiIyEgwsJBREEJg0a5zuJZbAjcbJf5vtD8kEt4NREREVRhYyChsj72O3b/fgEwqwUfjA6AyNzV0SUREZEQYWMjgErMKsXT3eQBA+KNdENTB1sAVERGRsWFgIYMqrVBjztbTuF2hxsBO9nhhkLehSyIiIiPEwEIG9e7eC7iUUQh7SzlWjfXnLLZERFQrBhYymB/OpmufEfTB0wFwtDIzcEVERGSsGFjIIFJvluDNHWcAAM8P6ohBXRwMXBERERkzBhZqdhVqDV75+jQKSysR4GGD14f4GLokIiIycgws1Oz+feAy4lLyYGVmgtXjA2Eq4/+GRER0dzxTULP6NSEbaw9fAQD888mefE4QERHVCwMLNZuswlLM3fY7hAAmBLfH8J4uhi6JiIhaCAYWahYajcBr3/yBnKJy+DhZYcnj3QxdEhERtSAMLNQsPv0lCb8m5MDMVIqPJwTCzFRm6JKIiKgFYWChJhd77Rb+9WM8AODtJ7qjs5OVgSsiIqKWhoGFmlR+SQVe/uo01BqBMH9XPN3bw9AlERFRC8TAQk1GCIF5UWeQlncb7W3NsXJUD0gknHqfiIj0x8BCTebLEyn44VwGTGUSfDwhEFZmpoYuiYiIWigGFmoSF9ML8M6eCwCAtx7zRU93G8MWRERELRoDCzW6kvJKzNkah/JKDQb7OGDaAC9Dl0RERC0cAws1umXfnceV7GI4WinwrzH+kEo5boWIiO4PAws1qt2/p+GbU9chkQCR4wJgZ6kwdElERNQKMLBQo7maU4yFO88BAF56pDP6e9sbuCIiImotGFioUZRXavDSV6dRVFaJvp62ePmRToYuiYiIWhEGFmoU7+27hLNp+bAxN0XkuACYyPi/FhERNR6eVei+RV/MxPojyQCA95/yh6uN0sAVERFRa8PAQvclI78Ur2//AwAwpb8nHu3mZOCKiIioNWJgoQZTawRe+fo0bpVUoLurNeYP8zV0SURE1EqZGLoAankq1Rr8kpCNL2Ku4UTyTVjIZfh4Qi8oTGSGLo2IiFopBhaqt8SsImyPTcXOuDRkFZYBACQSYOWTfvCytzBwdURE1JoxsNBdFZRWYM8f6dgem4rTKXna5bYWcowMcMPTfdzh62xtuAKJiKhNYGChGjQagZikXGw/lYp95zNQWqEBAMikEgz2ccBTQR54xNcRchMOgSIioubBwEJaqTdLsD32OnbEXkda3m3t8s6OlhjT2x0jA93gaGVmwAqJiKitYmBp40rKK/HD2Qxsj03F8aSb2uVWZiZ4wt8VY3p7wN9dBYmEDzAkIiLDYWBpg4QQiL12C9tPXcfes+koKqsEUDWAdmAnezwV5I7Q7s4wM+VdP0REZBwaNAhhzZo18PT0hJmZGYKDg3Hy5Mm7to+MjISPjw+USiU8PDwwd+5clJaWat8vLCzEq6++ig4dOkCpVKJ///747bffGlIa3UVGfinW/JyIf3xwGE+ti8G2U6koKqtEe1tzvPZoFxx56xFsfi4YIwLcGFaIiMio6H2FZdu2bQgPD8e6desQHByMyMhIhIaGIj4+Ho6OjjXab926FfPmzcOGDRvQv39/XL58GVOmTIFEIsGqVasAANOnT8e5c+ewefNmuLq6YsuWLQgJCcGFCxfg5uZ2/3vZhpVVqnHgQia2n7qOXxOyoRFVy5WmMgzzc8GY3u7o62kLqZRdPkREZLwkQgihzwrBwcHo06cPPv74YwCARqOBh4cHXnrpJcybN69G+zlz5uDixYuIjo7WLnvttddw4sQJHDlyBLdv34aVlRV2796N4cOHa9sEBQVh6NChePfdd+tVV0FBAVQqFfLz82FtzdtsASA+oxDPfHYcOUXl2mV9PNthTJAHhvV0gaWCPYJERGRY9T1/63XGKi8vR2xsLObPn69dJpVKERISgpiYmFrX6d+/P7Zs2YKTJ0+ib9++SEpKwvfff4+JEycCACorK6FWq2Fmpnv3iVKpxJEjR+qspaysDGVlZdrfCwoK9NmVNmHNz4nIKSqHk7UCTwW546kgD07wRkRELZJegSUnJwdqtRpOTroPuHNycsKlS5dqXWfChAnIycnBwIEDIYRAZWUlZs2ahQULFgAArKys0K9fPyxfvhxdu3aFk5MTvvrqK8TExKBTp0511hIREYG3335bn/LblILSCuw/nwEA+O+k3ujpbmPYgoiIiO5Dk8/8dejQIaxcuRKffPIJ4uLiEBUVhb1792L58uXaNps3b4YQAm5ublAoFPjoo48wfvx4SKV1lzd//nzk5+drX6mpqU29Ky3K3jPpKKvUoIuTJfzcVIYuh4iI6L7odYXF3t4eMpkMmZmZOsszMzPh7Oxc6zqLFy/GxIkTMX36dACAn58fiouLMXPmTCxcuBBSqRTe3t44fPgwiouLUVBQABcXF4wdOxYdO3assxaFQgGFQqFP+W3Kt7HXAQCje7lzDhUiImrx9LrCIpfLERQUpDOAVqPRIDo6Gv369at1nZKSkhpXSmSyqltm/z7e18LCAi4uLrh16xb279+PESNG6FMe3ZGcU4zYa7cglQCjAnmXFRERtXx63yYSHh6OyZMno3fv3ujbty8iIyNRXFyMqVOnAgAmTZoENzc3REREAADCwsKwatUqBAYGIjg4GImJiVi8eDHCwsK0wWX//v0QQsDHxweJiYl444034Ovrq90m6WfHnasrg7o4wNGaU+kTEVHLp3dgGTt2LLKzs7FkyRJkZGQgICAA+/bt0w7ETUlJ0bmismjRIkgkEixatAhpaWlwcHBAWFgYVqxYoW2Tn5+P+fPn4/r167C1tcXo0aOxYsUKmJqaNsIuti1qjcCOuDvdQUHuBq6GiIioceg9D4ux4jwsVY4k5ODZ9SdgbWaCkwtDOGMtEREZtfqev5v8LiFqXtVXV54IcGVYISKiVoOBpRUpLK3AD+fSAVTdHURERNRaMLC0It+fTUdphQbeDhYI8LAxdDlERESNhoGlFdkRmwYAeCrIg3OvEBFRq8LA0kpczSnGyas3OfcKERG1SgwsrUTUncG2Azs7wFnFuVeIiKh1YWBpBTQagR1x1d1BHGxLREStDwNLK3A8ORdpebdhZWaCId2c7r0CERFRC8PA0gpUP+jw8Z6ce4WIiFonBpYWrrisEvvOZQBgdxAREbVeDCwt3Pdn01FSrkZHewv0am9j6HKIiIiaBANLC1fdHTQ6yJ1zrxARUavFwNKCpd4swYnkm5Bw7hUiImrlGFhasOoHHQ7sZA9XG6WBqyEiImo6DCwtVNXcK3e6g/igQyIiauUYWFqok1dvIvXmbVgqTBDa3dnQ5RARETUpBpYWaod27hUXKOWce4WIiFo3BpYWqLisEnvPpgOoujuIiIiotWNgaYH2nctASbkaHezM0btDO0OXQ0RE1OQYWFqg6sG2T/Xi3CtERNQ2MLC0MNdvleDYlVwAwKhenHuFiIjaBgaWFiYqLg0A0N/bDu7tzA1cDRERUfNgYGlBhPhz7hU+6JCIiNoSBpYW5NS1W7iWWwILuQyP9eDcK0RE1HYwsLQg356quroyzM8F5nITA1dDRETUfBhYWojb5Wrt3CvsDiIioraGgaWF2H8+A0VllfCwVaKPp62hyyEiImpWDCwtxLexfz7oUCrl3CtERNS2MLC0ADfybuPolRwAfDIzERG1TQwsLcDO02kQAgj2soWHLedeISKitoeBxcgJIbTdQRxsS0REbRUDi5GLS7mF5JximMtlGObnYuhyiIiIDIKBxch9G1s1Ff/QHi6wUHDuFSIiapsYWIxYaYUae/64AQAYHcQHHRIRUdvFwGLE9p/PQGFZJdxslHjAy87Q5RARERkMA4sR23Hnycyjgzj3ChERtW0MLEYqI78URxKyAQCje7E7iIiI2jYGFiMVdfo6NALo62mLDnYWhi6HiIjIoBhYjJAQAjs49woREZEWA4sR+j01D1eyi2FmKsVQP2dDl0NERGRwDCxGqHpm26E9XGBlZmrgaoiIiAyPgcXIlFao8b87c6+wO4iIiKhKgwLLmjVr4OnpCTMzMwQHB+PkyZN3bR8ZGQkfHx8olUp4eHhg7ty5KC0t1b6vVquxePFieHl5QalUwtvbG8uXL4cQoiHltWgHL2aioLQSrioz9OvIuVeIiIgAQO+53rdt24bw8HCsW7cOwcHBiIyMRGhoKOLj4+Ho6Fij/datWzFv3jxs2LAB/fv3x+XLlzFlyhRIJBKsWrUKAPDee+9h7dq12LRpE7p3745Tp05h6tSpUKlUePnll+9/L1uQ6u6gJ3tx7hUiIqJqel9hWbVqFWbMmIGpU6eiW7duWLduHczNzbFhw4Za2x87dgwDBgzAhAkT4OnpiSFDhmD8+PE6V2WOHTuGESNGYPjw4fD09MRTTz2FIUOG3PPKTWuTWVCKXy7fmXuF3UFERERaegWW8vJyxMbGIiQk5M8NSKUICQlBTExMrev0798fsbGx2vCRlJSE77//HsOGDdNpEx0djcuXLwMA/vjjDxw5cgRDhw6ts5aysjIUFBTovFq6XafToBFAUId28LLn3CtERETV9OoSysnJgVqthpOTk85yJycnXLp0qdZ1JkyYgJycHAwcOBBCCFRWVmLWrFlYsGCBts28efNQUFAAX19fyGQyqNVqrFixAs8880ydtURERODtt9/Wp3yjJoTQdgdxsC0REZGuJr9L6NChQ1i5ciU++eQTxMXFISoqCnv37sXy5cu1bb755ht8+eWX2Lp1K+Li4rBp0yb861//wqZNm+rc7vz585Gfn699paamNvWuNKkz1/ORkFUEhYkUw3u6GLocIiIio6LXFRZ7e3vIZDJkZmbqLM/MzISzc+0TnC1evBgTJ07E9OnTAQB+fn4oLi7GzJkzsXDhQkilUrzxxhuYN28exo0bp21z7do1REREYPLkybVuV6FQQKFQ6FO+UdsRV3V1JbS7M6w59woREZEOva6wyOVyBAUFITo6WrtMo9EgOjoa/fr1q3WdkpISSKW6HyOTyQBAe9tyXW00Go0+5bVYZZVq7P6dc68QERHVRe/bmsPDwzF58mT07t0bffv2RWRkJIqLizF16lQAwKRJk+Dm5oaIiAgAQFhYGFatWoXAwEAEBwcjMTERixcvRlhYmDa4hIWFYcWKFWjfvj26d++O06dPY9WqVZg2bVoj7qrxir6YhfzbFXC2NsOATvaGLoeIiMjo6B1Yxo4di+zsbCxZsgQZGRkICAjAvn37tANxU1JSdK6WLFq0CBKJBIsWLUJaWhocHBy0AaXa6tWrsXjxYrz44ovIysqCq6srnn/+eSxZsqQRdtH4VT/ocFQvN8g49woREVENEtFKppMtKCiASqVCfn4+rK2tDV1OvWUVlqJfxE9QawQOhg9CJ0dLQ5dERETUbOp7/uazhAxs9+kbUGsEAtvbMKwQERHVgYHFgDj3ChERUf0wsBhQYlYR4jMLITeR4vGeroYuh4iIyGgxsBhQTFIuAKCvpy1USs69QkREVBcGFgM6kXQTABDsZWvgSoiIiIwbA4uBCCFwIrnqCktwRzsDV0NERGTcGFgM5Ep2MXKKyqEwkcLfQ2XocoiIiIwaA4uBHL8zfiWwvQ0UJjIDV0NERGTcGFgM5ERy9fgVdgcRERHdCwOLAQghcOLOFZYHOH6FiIjonhhYDOBqbgmyCssgl0kR2N7G0OUQEREZPQYWA6i+uhLgYQMzU45fISIiuhcGFgPQjl/pyPlXiIiI6oOBpZn9dfwKB9wSERHVDwNLM7t+6zZu5JfCRCpBrw42hi6HiIioRWBgaWbV86/0dFfBXG5i4GqIiIhaBgaWZvbn+BV2BxEREdUXA0sz0z4/iA88JCIiqjcGlmaUlncbqTdvQyaVoLcnAwsREVF9MbA0o+q7g3q4WsNSwfErRERE9cXA0oxOJHH8ChERUUMwsDQjjl8hIiJqGAaWZpJZUIqruSWQSsDxK0RERHpiYGkm1fOvdHO1hkppauBqiIiIWhYGlmainX+F0/ETERHpjYGlmfz5/CB2BxEREemLgaUZZBeW4Up2MSQSoC8DCxERkd4YWJrByTvdQT5OVrAxlxu4GiIiopaHgaUZVN/O/ADnXyEiImoQBpZmoJ0wjt1BREREDcLA0sRuFpcjPrMQAMevEBERNRQDSxM7eac7qLOjJewsFQauhoiIqGViYGlix7XPD+LVFSIiooZiYGlinDCOiIjo/jGwNKH8kgpcyigAwCssRERE94OBpQmdvHoTQgAdHSzgaGVm6HKIiIhaLAaWJvTndPzsDiIiIrofDCxNqHr8ygPsDiIiIrovDCxNpKC0Audv5APgFRYiIqL7xcDSRGKv3oJGAB3szOGs4vgVIiKi+8HA0kSOJ1ePX2F3EBER0f1iYGkifz4/iN1BRERE96tBgWXNmjXw9PSEmZkZgoODcfLkybu2j4yMhI+PD5RKJTw8PDB37lyUlpZq3/f09IREIqnxmj17dkPKM7iiskqcTbszfoUDbomIiO6bib4rbNu2DeHh4Vi3bh2Cg4MRGRmJ0NBQxMfHw9HRsUb7rVu3Yt68ediwYQP69++Py5cvY8qUKZBIJFi1ahUA4LfffoNardauc+7cOTz66KMYM2bMfeya4cReuwW1RsDNRgn3duaGLoeIiKjF0/sKy6pVqzBjxgxMnToV3bp1w7p162Bubo4NGzbU2v7YsWMYMGAAJkyYAE9PTwwZMgTjx4/XuSrj4OAAZ2dn7WvPnj3w9vbGoEGDGr5nBqSdf4VXV4iIiBqFXoGlvLwcsbGxCAkJ+XMDUilCQkIQExNT6zr9+/dHbGysNqAkJSXh+++/x7Bhw+r8jC1btmDatGmQSCR11lJWVoaCggKdl7HQzr/C8StERESNQq8uoZycHKjVajg5Oeksd3JywqVLl2pdZ8KECcjJycHAgQMhhEBlZSVmzZqFBQsW1Np+165dyMvLw5QpU+5aS0REBN5++219ym8Wt8vVOHM9DwDwQEcGFiIiosbQ5HcJHTp0CCtXrsQnn3yCuLg4REVFYe/evVi+fHmt7devX4+hQ4fC1dX1rtudP38+8vPzta/U1NSmKF9vcSm3UKEWcFGZwcNWaehyiIiIWgW9rrDY29tDJpMhMzNTZ3lmZiacnZ1rXWfx4sWYOHEipk+fDgDw8/NDcXExZs6ciYULF0Iq/TMzXbt2DQcPHkRUVNQ9a1EoFFAoFPqU3yz+fH6Q7V27tIiIiKj+9LrCIpfLERQUhOjoaO0yjUaD6Oho9OvXr9Z1SkpKdEIJAMhkMgCAEEJn+caNG+Ho6Ijhw4frU5ZROX5n/Eowu4OIiIgajd63NYeHh2Py5Mno3bs3+vbti8jISBQXF2Pq1KkAgEmTJsHNzQ0REREAgLCwMKxatQqBgYEIDg5GYmIiFi9ejLCwMG1wAaqCz8aNGzF58mSYmOhdllEorVDj99Q8AJzhloiIqDHpnQzGjh2L7OxsLFmyBBkZGQgICMC+ffu0A3FTUlJ0rqgsWrQIEokEixYtQlpaGhwcHBAWFoYVK1bobPfgwYNISUnBtGnT7nOXDOf31DyUV2rgYKWAl72FocshIiJqNSTi7/0yLVRBQQFUKhXy8/NhbW1tkBo+PJiAfx+8jMd7uuDjCb0MUgMREVFLUt/zN58l1IhOVD/wkONXiIiIGhUDSyMpq1Qj9totAMADHL9CRETUqBhYGsmZ6/koq9TAzkKOTo6Whi6HiIioVWFgaSTV86/05fwrREREjY6BpZFUPz+ItzMTERE1PgaWRlCh1vw5fsWbA26JiIgaGwNLIziblo+ScjVszE3RxdHK0OUQERG1OgwsjeBEUlV3UF9PW0ilHL9CRETU2BhYGgHnXyEiImpaDCz3qVKtwamrVeNXOOCWiIioaTCw3KcL6QUoKquElZkJuroY5pEARERErR0Dy3366/gVGcevEBERNQkGlvv05/gVdgcRERE1FQaW+6DWiL9MGMcBt0RERE2FgeU+XEwvQGFpJSwVJujuyvErRERETYWB5T5UX10J6tAOJjL+URIRETUVnmXvQ/UDDzl+hYiIqGkxsDSQRiNw8mrVFZYHOGEcERFRk2JgaaDLWYXIK6mAuVwGPzeVocshIiJq1RhYGqh6/pWgDu1gyvErRERETYpn2gbSzr/C6fiJiIiaHANLAwghcLJ6/hWOXyEiImpyDCwNcCW7CDlF5VCYSNHTneNXiIiImhoDSwMcvzN+pVf7dlCYyAxcDRERUevHwNIA2un4Of8KERFRs2Bg0ZMQAserJ4zj84OIiIiaBQOLnpJzipFdWAa5TIrA9jaGLoeIiKhNYGDRU3V3UICHDcxMOX6FiIioOTCw6InPDyIiImp+DCx6EEJor7Dw+UFERETNh4FFD6k3byM9vxSmMgl6tW9n6HKIiIjaDAYWPRy/Mx1/T3cbKOUcv0JERNRcGFj0UP3AQz4/iIiIqHkxsOhB+8BDjl8hIiJqVgws9ZSWdxvXb92GTCpBUAeOXyEiImpODCz1VH07cw83FSwVJgauhoiIqG1hYKmn6un4H+D4FSIiombHwFJPfOAhERGR4TCw1ENGfimu5ZZAKgF6ezKwEBERNTcGlnqovjuom6s1rM1MDVwNERFR28PAUg/HtfOv8HZmIiIiQ2BgqYfqKyx8fhAREZFhNCiwrFmzBp6enjAzM0NwcDBOnjx51/aRkZHw8fGBUqmEh4cH5s6di9LSUp02aWlpePbZZ2FnZwelUgk/Pz+cOnWqIeU1qqzCUiRlF0MiAfpy/AoREZFB6D2hyLZt2xAeHo5169YhODgYkZGRCA0NRXx8PBwdHWu037p1K+bNm4cNGzagf//+uHz5MqZMmQKJRIJVq1YBAG7duoUBAwZg8ODB+OGHH+Dg4ICEhAS0a2f4CdpO3rk7yNfZGipzjl8hIiIyBL0Dy6pVqzBjxgxMnToVALBu3Trs3bsXGzZswLx582q0P3bsGAYMGIAJEyYAADw9PTF+/HicOHFC2+a9996Dh4cHNm7cqF3m5eWl9840BT4/iIiIyPD06hIqLy9HbGwsQkJC/tyAVIqQkBDExMTUuk7//v0RGxur7TZKSkrC999/j2HDhmnbfPfdd+jduzfGjBkDR0dHBAYG4r///e9daykrK0NBQYHOqyn8OX6FgYWIiMhQ9AosOTk5UKvVcHJy0lnu5OSEjIyMWteZMGEC3nnnHQwcOBCmpqbw9vbGww8/jAULFmjbJCUlYe3atejcuTP279+PF154AS+//DI2bdpUZy0RERFQqVTal4eHhz67Ui+lFWoIgarxK7xDiIiIyGCa/C6hQ4cOYeXKlfjkk08QFxeHqKgo7N27F8uXL9e20Wg06NWrF1auXInAwEDMnDkTM2bMwLp16+rc7vz585Gfn699paamNnrtZqYyHAgfhLhFj8LWQt7o2yciIqL60WsMi729PWQyGTIzM3WWZ2ZmwtnZudZ1Fi9ejIkTJ2L69OkAAD8/PxQXF2PmzJlYuHAhpFIpXFxc0K1bN531unbtih07dtRZi0KhgEKh0Kf8BmvHsEJERGRQel1hkcvlCAoKQnR0tHaZRqNBdHQ0+vXrV+s6JSUlkEp1P0YmkwEAhBAAgAEDBiA+Pl6nzeXLl9GhQwd9yiMiIqJWSu+7hMLDwzF58mT07t0bffv2RWRkJIqLi7V3DU2aNAlubm6IiIgAAISFhWHVqlUIDAxEcHAwEhMTsXjxYoSFhWmDy9y5c9G/f3+sXLkSTz/9NE6ePIn//Oc/+M9//tOIu0pEREQtld6BZezYscjOzsaSJUuQkZGBgIAA7Nu3TzsQNyUlReeKyqJFiyCRSLBo0SKkpaXBwcEBYWFhWLFihbZNnz59sHPnTsyfPx/vvPMOvLy8EBkZiWeeeaYRdpGIiIhaOomo7pdp4QoKCqBSqZCfnw9ra2tDl0NERET1UN/zN58lREREREaPgYWIiIiMHgMLERERGT0GFiIiIjJ6DCxERERk9BhYiIiIyOgxsBAREZHRY2AhIiIio8fAQkREREZP76n5jVX1hL0FBQUGroSIiIjqq/q8fa+J91tNYCksLAQAeHh4GLgSIiIi0ldhYSFUKlWd77eaZwlpNBrcuHEDVlZWkEgkhi6nyRQUFMDDwwOpqamt/plJ3NfWqy3tL/e19WpL+9uU+yqEQGFhIVxdXXUenvx3reYKi1Qqhbu7u6HLaDbW1tat/gtSjfvaerWl/eW+tl5taX+bal/vdmWlGgfdEhERkdFjYCEiIiKjx8DSwigUCixduhQKhcLQpTQ57mvr1Zb2l/vaerWl/TWGfW01g26JiIio9eIVFiIiIjJ6DCxERERk9BhYiIiIyOgxsBAREZHRY2AxIhEREejTpw+srKzg6OiIkSNHIj4+/q7rfP7555BIJDovMzOzZqq44ZYtW1ajbl9f37uus337dvj6+sLMzAx+fn74/vvvm6na++fp6VljfyUSCWbPnl1r+5Z0XH/55ReEhYXB1dUVEokEu3bt0nlfCIElS5bAxcUFSqUSISEhSEhIuOd216xZA09PT5iZmSE4OBgnT55soj2ov7vta0VFBd566y34+fnBwsICrq6umDRpEm7cuHHXbTbku9Bc7nVsp0yZUqP2xx577J7bbWnHFkCt31+JRIL333+/zm0a67Gtz7mmtLQUs2fPhp2dHSwtLTF69GhkZmbedbsN/a7XFwOLETl8+DBmz56N48eP48CBA6ioqMCQIUNQXFx81/Wsra2Rnp6ufV27dq2ZKr4/3bt316n7yJEjdbY9duwYxo8fj+eeew6nT5/GyJEjMXLkSJw7d64ZK2643377TWdfDxw4AAAYM2ZMneu0lONaXFwMf39/rFmzptb3/+///g8fffQR1q1bhxMnTsDCwgKhoaEoLS2tc5vbtm1DeHg4li5diri4OPj7+yM0NBRZWVlNtRv1crd9LSkpQVxcHBYvXoy4uDhERUUhPj4eTzzxxD23q893oTnd69gCwGOPPaZT+1dffXXXbbbEYwtAZx/T09OxYcMGSCQSjB49+q7bNcZjW59zzdy5c/G///0P27dvx+HDh3Hjxg08+eSTd91uQ77rehFktLKysgQAcfjw4TrbbNy4UahUquYrqpEsXbpU+Pv717v9008/LYYPH66zLDg4WDz//PONXFnzeOWVV4S3t7fQaDS1vt9SjysAsXPnTu3vGo1GODs7i/fff1+7LC8vTygUCvHVV1/VuZ2+ffuK2bNna39Xq9XC1dVVRERENEndDfH3fa3NyZMnBQBx7dq1Otvo+10wlNr2d/LkyWLEiBF6bae1HNsRI0aIRx555K5tWsqx/fu5Ji8vT5iamort27dr21y8eFEAEDExMbVuo6HfdX3wCosRy8/PBwDY2tretV1RURE6dOgADw8PjBgxAufPn2+O8u5bQkICXF1d0bFjRzzzzDNISUmps21MTAxCQkJ0loWGhiImJqapy2x05eXl2LJlC6ZNm3bXB3W21OP6V8nJycjIyNA5diqVCsHBwXUeu/LycsTGxuqsI5VKERIS0uKOd35+PiQSCWxsbO7aTp/vgrE5dOgQHB0d4ePjgxdeeAG5ubl1tm0txzYzMxN79+7Fc889d8+2LeHY/v1cExsbi4qKCp3j5Ovri/bt29d5nBryXdcXA4uR0mg0ePXVVzFgwAD06NGjznY+Pj7YsGEDdu/ejS1btkCj0aB///64fv16M1arv+DgYHz++efYt28f1q5di+TkZDz44IMoLCystX1GRgacnJx0ljk5OSEjI6M5ym1Uu3btQl5eHqZMmVJnm5Z6XP+u+vjoc+xycnKgVqtb/PEuLS3FW2+9hfHjx9/1YXH6fheMyWOPPYYvvvgC0dHReO+993D48GEMHToUarW61vat5dhu2rQJVlZW9+wiaQnHtrZzTUZGBuRyeY2gfbfj1JDvur5azdOaW5vZs2fj3Llz9+zv7NevH/r166f9vX///ujatSs+/fRTLF++vKnLbLChQ4dqf+7ZsyeCg4PRoUMHfPPNN/X6V0tLtn79egwdOhSurq51tmmpx5WqVFRU4Omnn4YQAmvXrr1r25b8XRg3bpz2Zz8/P/Ts2RPe3t44dOgQ/vGPfxiwsqa1YcMGPPPMM/ccCN8Sjm19zzXGgFdYjNCcOXOwZ88e/Pzzz3B3d9drXVNTUwQGBiIxMbGJqmsaNjY26NKlS511Ozs71xihnpmZCWdn5+Yor9Fcu3YNBw8exPTp0/Var6Ue1+rjo8+xs7e3h0wma7HHuzqsXLt2DQcOHLjr1ZXa3Ou7YMw6duwIe3v7Omtv6ccWAH799VfEx8fr/R0GjO/Y1nWucXZ2Rnl5OfLy8nTa3+04NeS7ri8GFiMihMCcOXOwc+dO/PTTT/Dy8tJ7G2q1GmfPnoWLi0sTVNh0ioqKcOXKlTrr7tevH6Kjo3WWHThwQOcqREuwceNGODo6Yvjw4Xqt11KPq5eXF5ydnXWOXUFBAU6cOFHnsZPL5QgKCtJZR6PRIDo62uiPd3VYSUhIwMGDB2FnZ6f3Nu71XTBm169fR25ubp21t+RjW239+vUICgqCv7+/3usay7G917kmKCgIpqamOscpPj4eKSkpdR6nhnzXG1I4GYkXXnhBqFQqcejQIZGenq59lZSUaNtMnDhRzJs3T/v722+/Lfbv3y+uXLkiYmNjxbhx44SZmZk4f/68IXah3l577TVx6NAhkZycLI4ePSpCQkKEvb29yMrKEkLU3M+jR48KExMT8a9//UtcvHhRLF26VJiamoqzZ88aahf0plarRfv27cVbb71V472WfFwLCwvF6dOnxenTpwUAsWrVKnH69GntnTH//Oc/hY2Njdi9e7c4c+aMGDFihPDy8hK3b9/WbuORRx4Rq1ev1v7+9ddfC4VCIT7//HNx4cIFMXPmTGFjYyMyMjKaff/+6m77Wl5eLp544gnh7u4ufv/9d53vcFlZmXYbf9/Xe30XDOlu+1tYWChef/11ERMTI5KTk8XBgwdFr169ROfOnUVpaal2G63h2FbLz88X5ubmYu3atbVuo6Uc2/qca2bNmiXat28vfvrpJ3Hq1CnRr18/0a9fP53t+Pj4iKioKO3v9fmu3w8GFiMCoNbXxo0btW0GDRokJk+erP391VdfFe3btxdyuVw4OTmJYcOGibi4uOYvXk9jx44VLi4uQi6XCzc3NzF27FiRmJioff/v+ymEEN98843o0qWLkMvlonv37mLv3r3NXPX92b9/vwAg4uPja7zXko/rzz//XOv/t9X7o9FoxOLFi4WTk5NQKBTiH//4R40/gw4dOoilS5fqLFu9erX2z6Bv377i+PHjzbRHdbvbviYnJ9f5Hf7555+12/j7vt7ru2BId9vfkpISMWTIEOHg4CBMTU1Fhw4dxIwZM2oEj9ZwbKt9+umnQqlUiry8vFq30VKObX3ONbdv3xYvvviiaNeunTA3NxejRo0S6enpNbbz13Xq812/H5I7H0pERERktDiGhYiIiIweAwsREREZPQYWIiIiMnoMLERERGT0GFiIiIjI6DGwEBERkdFjYCEiIiKjx8BCRK3SoUOHIJFIajwPhYhaJgYWIiIiMnoMLERERGT0GFiIqEloNBpERETAy8sLSqUS/v7++PbbbwH82V2zd+9e9OzZE2ZmZnjggQdw7tw5nW3s2LED3bt3h0KhgKenJz744AOd98vKyvDWW2/Bw8MDCoUCnTp1wvr163XaxMbGonfv3jA3N0f//v0RHx/ftDtORE2CgYWImkRERAS++OILrFu3DufPn8fcuXPx7LPP4vDhw9o2b7zxBj744AP89ttvcHBwQFhYGCoqKgBUBY2nn34a48aNw9mzZ7Fs2TIsXrwYn3/+uXb9SZMm4auvvsJHH32Eixcv4tNPP4WlpaVOHQsXLsQHH3yAU6dOwcTEBNOmTWuW/SeiRtZoj1EkIrqjtLRUmJubi2PHjuksf+6558T48eO1T8b9+uuvte/l5uYKpVIptm3bJoQQYsKECeLRRx/VWf+NN94Q3bp1E0IIER8fLwCIAwcO1FpD9WccPHhQu2zv3r0CQKM97p6Img+vsBBRo0tMTERJSQkeffRRWFpaal9ffPEFrly5om3Xr18/7c+2trbw8fHBxYsXAQAXL17EgAEDdLY7YMAAJCQkQK1W4/fff4dMJsOgQYPuWkvPnj21P7u4uAAAsrKy7nsfiah5mRi6ACJqfYqKigAAe/fuhZubm857CoVCJ7Q0lFKprFc7U1NT7c8SiQRA1fgaImpZeIWFiBpdt27doFAokJKSgk6dOum8PDw8tO2OHz+u/fnWrVu4fPkyunbtCgDo2rUrjh49qrPdo0ePokuXLpDJZPDz84NGo9EZE0NErRevsBBRo7OyssLrr7+OuXPnQqPRYODAgcjPz8fRo0dhbW2NDh06AADeeecd2NnZwcnJCQsXLoS9vT1GjhwJAHjttdfQp08fLF++HGPHjkVMTAw+/vhjfPLJJwAAT09PTJ48GdOmTcNHH30Ef39/XLt2DVlZWXj66acNtetE1EQYWIioSSxfvhwODg6IiIhAUlISbGxs0KtXLyxYsEDbJfPPf/4Tr7zyChISEhAQEID//e9/kMvlAIBevXrhm2++wZIlS7B8+XK4uLjgnXfewZQpU7SfsXbtWixYsAAvvvgicnNz0b59eyxYsMAQu0tETUwihBCGLoKI2pZDhw5h8ODBuHXrFmxsbAxdDhG1ABzDQkREREaPgYWIiIiMHruEiIiIyOjxCgsREREZPQYWIiIiMnoMLERERGT0GFiIiIjI6DGwEBERkdFjYCEiIiKjx8BCRERERo+BhYiIiIweAwsREREZvf8H5E0QKZOYEX0AAAAASUVORK5CYII=\n"
          },
          "metadata": {}
        }
      ]
    }
  ]
}